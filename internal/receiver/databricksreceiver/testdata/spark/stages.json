[ {
  "status" : "COMPLETE",
  "stageId" : 396,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:59:56.443GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:59:56.456GMT",
  "completionTime" : "2022-12-20T20:59:56.497GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7706979,
  "executorRunTime" : 1,
  "executorCpuTime" : 16625938,
  "resultSize" : 7115,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 11,
  "diskBytesSpilled" : 13,
  "peakExecutionMemory" : 0,
  "inputBytes" : 3,
  "inputRecords" : 5,
  "outputBytes" : 7,
  "outputRecords" : 9,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 858,
  "shuffleReadBytes" : 858,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1428, 1427 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 395,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 2,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 12,
  "diskBytesSpilled" : 14,
  "peakExecutionMemory" : 0,
  "inputBytes" : 4,
  "inputRecords" : 6,
  "outputBytes" : 8,
  "outputRecords" : 10,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 1426, 1424, 1417, 1425, 1421, 1418, 1423, 1420, 1422, 1419 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 394,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1416, 1415, 1414, 1413, 1412, 1411, 1410 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 393,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:59:56.352GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:59:56.385GMT",
  "completionTime" : "2022-12-20T20:59:56.433GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9803705,
  "executorRunTime" : 21,
  "executorCpuTime" : 18574556,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 7,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 16230,
  "shuffleReadBytes" : 16230,
  "shuffleReadRecords" : 38,
  "shuffleWriteBytes" : 858,
  "shuffleWriteTime" : 340109,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1426, 1424, 1417, 1425, 1421, 1418, 1423, 1420, 1422, 1419 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 392,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1416, 1415, 1414, 1413, 1412, 1411, 1410 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 391,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:59:56.066GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:59:56.074GMT",
  "completionTime" : "2022-12-20T20:59:56.161GMT",
  "executorDeserializeTime" : 24,
  "executorDeserializeCpuTime" : 24927894,
  "executorRunTime" : 81,
  "executorCpuTime" : 18850226,
  "resultSize" : 20876,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 88284,
  "inputRecords" : 32,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 16230,
  "shuffleWriteTime" : 3262986,
  "shuffleWriteRecords" : 38,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1416, 1415, 1414, 1413, 1412, 1411, 1410 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 390,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:59:55.620GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:59:55.629GMT",
  "completionTime" : "2022-12-20T20:59:55.704GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2342764,
  "executorRunTime" : 58,
  "executorCpuTime" : 2425653,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70559,
  "inputRecords" : 32,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1409, 1407, 1408 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 389,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:59:54.892GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:59:54.902GMT",
  "completionTime" : "2022-12-20T20:59:55.151GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9628967,
  "executorRunTime" : 224,
  "executorCpuTime" : 107242544,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12125,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1406 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 388,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 1404, 1399, 1401, 1403, 1396, 1400, 1398, 1397 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 387,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:59:54.849GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:59:54.851GMT",
  "completionTime" : "2022-12-20T20:59:54.877GMT",
  "executorDeserializeTime" : 12,
  "executorDeserializeCpuTime" : 14876611,
  "executorRunTime" : 36,
  "executorCpuTime" : 27995194,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4231,
  "shuffleWriteTime" : 225108,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1404, 1399, 1401, 1403, 1396, 1400, 1398, 1397 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 386,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:58:56.421GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:58:56.434GMT",
  "completionTime" : "2022-12-20T20:58:56.475GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7582798,
  "executorRunTime" : 17,
  "executorCpuTime" : 16110758,
  "resultSize" : 7113,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 858,
  "shuffleReadBytes" : 858,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1391, 1390 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 385,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 1389, 1381, 1388, 1383, 1385, 1382, 1380, 1386, 1384, 1387 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 384,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1379, 1374, 1378, 1375, 1373, 1377, 1376 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 383,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:58:56.329GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:58:56.365GMT",
  "completionTime" : "2022-12-20T20:58:56.411GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7546897,
  "executorRunTime" : 21,
  "executorCpuTime" : 18472617,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 5,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 14505,
  "shuffleReadBytes" : 14505,
  "shuffleReadRecords" : 36,
  "shuffleWriteBytes" : 858,
  "shuffleWriteTime" : 340408,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1389, 1381, 1388, 1383, 1385, 1382, 1380, 1386, 1384, 1387 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 382,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1379, 1374, 1378, 1375, 1373, 1377, 1376 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 381,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 5,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 5,
  "submissionTime" : "2022-12-20T20:58:56.037GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:58:56.044GMT",
  "completionTime" : "2022-12-20T20:58:56.139GMT",
  "executorDeserializeTime" : 18,
  "executorDeserializeCpuTime" : 19844189,
  "executorRunTime" : 87,
  "executorCpuTime" : 13965740,
  "resultSize" : 15020,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 88284,
  "inputRecords" : 32,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 14505,
  "shuffleWriteTime" : 1653344,
  "shuffleWriteRecords" : 36,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1379, 1374, 1378, 1375, 1373, 1377, 1376 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 380,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:58:55.579GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:58:55.587GMT",
  "completionTime" : "2022-12-20T20:58:55.666GMT",
  "executorDeserializeTime" : 3,
  "executorDeserializeCpuTime" : 3418251,
  "executorRunTime" : 57,
  "executorCpuTime" : 2712573,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70559,
  "inputRecords" : 32,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1372, 1370, 1371 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 379,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:58:54.890GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:58:54.899GMT",
  "completionTime" : "2022-12-20T20:58:55.141GMT",
  "executorDeserializeTime" : 11,
  "executorDeserializeCpuTime" : 11396962,
  "executorRunTime" : 217,
  "executorCpuTime" : 103208005,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12123,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1369 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 378,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 1367, 1360, 1364, 1361, 1363, 1362, 1359, 1366 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 377,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:58:54.841GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:58:54.845GMT",
  "completionTime" : "2022-12-20T20:58:54.876GMT",
  "executorDeserializeTime" : 26,
  "executorDeserializeCpuTime" : 15945785,
  "executorRunTime" : 59,
  "executorCpuTime" : 28674888,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4223,
  "shuffleWriteTime" : 192805,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1367, 1360, 1364, 1361, 1363, 1362, 1359, 1366 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 376,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:57:55.810GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:57:55.823GMT",
  "completionTime" : "2022-12-20T20:57:55.862GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7477009,
  "executorRunTime" : 16,
  "executorCpuTime" : 15311078,
  "resultSize" : 7117,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1354, 1353 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 375,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 1352, 1349, 1350, 1345, 1347, 1344, 1343, 1351, 1348, 1346 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 374,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1342, 1337, 1341, 1336, 1338, 1339, 1340 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 373,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:57:55.712GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:57:55.740GMT",
  "completionTime" : "2022-12-20T20:57:55.796GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8295313,
  "executorRunTime" : 30,
  "executorCpuTime" : 27475312,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 3,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 12788,
  "shuffleReadBytes" : 12788,
  "shuffleReadRecords" : 34,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 328109,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1352, 1349, 1350, 1345, 1347, 1344, 1343, 1351, 1348, 1346 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 372,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1342, 1337, 1341, 1336, 1338, 1339, 1340 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 371,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 3,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 3,
  "submissionTime" : "2022-12-20T20:57:55.525GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:57:55.533GMT",
  "completionTime" : "2022-12-20T20:57:55.618GMT",
  "executorDeserializeTime" : 11,
  "executorDeserializeCpuTime" : 12270099,
  "executorRunTime" : 70,
  "executorCpuTime" : 57384492,
  "resultSize" : 9164,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 88284,
  "inputRecords" : 32,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 12788,
  "shuffleWriteTime" : 1311237,
  "shuffleWriteRecords" : 34,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1342, 1337, 1341, 1336, 1338, 1339, 1340 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 370,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:57:55.093GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:57:55.098GMT",
  "completionTime" : "2022-12-20T20:57:55.173GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2092053,
  "executorRunTime" : 58,
  "executorCpuTime" : 2724881,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70559,
  "inputRecords" : 32,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1335, 1333, 1334 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 369,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:57:54.486GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:57:54.495GMT",
  "completionTime" : "2022-12-20T20:57:54.751GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7607118,
  "executorRunTime" : 232,
  "executorCpuTime" : 120158211,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12130,
  "outputRecords" : 9,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1332 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 368,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 1330, 1323, 1326, 1329, 1322, 1324, 1327, 1325 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 367,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:57:54.441GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:57:54.444GMT",
  "completionTime" : "2022-12-20T20:57:54.472GMT",
  "executorDeserializeTime" : 31,
  "executorDeserializeCpuTime" : 18054365,
  "executorRunTime" : 46,
  "executorCpuTime" : 32670760,
  "resultSize" : 26064,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 268697600,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4864,
  "shuffleWriteTime" : 239905,
  "shuffleWriteRecords" : 9,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1330, 1323, 1326, 1329, 1322, 1324, 1327, 1325 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 366,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:56:56.268GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:56:56.282GMT",
  "completionTime" : "2022-12-20T20:56:56.428GMT",
  "executorDeserializeTime" : 10,
  "executorDeserializeCpuTime" : 10723777,
  "executorRunTime" : 117,
  "executorCpuTime" : 47175803,
  "resultSize" : 5397,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 19154,
  "shuffleReadBytes" : 19154,
  "shuffleReadRecords" : 32,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at CheckpointsEdge.scala:313",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.rdd.RDD.collect(RDD.scala:1025)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$2(CheckpointsEdge.scala:313)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.withDmqTag(CheckpointsEdge.scala:177)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$1(CheckpointsEdge.scala:193)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.writeCheckpoint(CheckpointsEdge.scala:193)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles(CheckpointsEdge.scala:173)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles$(CheckpointsEdge.scala:171)\ncom.databricks.sql.transaction.tahoe.DeltaLog.writeCheckpointFiles(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog(Checkpoints.scala:357)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog$(Checkpoints.scala:351)\ncom.databricks.sql.transaction.tahoe.DeltaLog.checkpointAndCleanUpDeltaLog(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.$anonfun$checkpoint$2(Checkpoints.scala:325)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1321, 1320, 1319 ],
  "accumulatorUpdates" : [ {
    "id" : 13550,
    "name" : "checkpointSizeRows",
    "value" : "32"
  }, {
    "id" : 13553,
    "name" : "checkpointSizeInBytes",
    "value" : "56285"
  }, {
    "id" : 13551,
    "name" : "numOfFiles",
    "value" : "30"
  } ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 365,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at CheckpointsEdge.scala:309",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$2(CheckpointsEdge.scala:309)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.withDmqTag(CheckpointsEdge.scala:177)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$1(CheckpointsEdge.scala:193)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.writeCheckpoint(CheckpointsEdge.scala:193)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles(CheckpointsEdge.scala:173)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles$(CheckpointsEdge.scala:171)\ncom.databricks.sql.transaction.tahoe.DeltaLog.writeCheckpointFiles(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog(Checkpoints.scala:357)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog$(Checkpoints.scala:351)\ncom.databricks.sql.transaction.tahoe.DeltaLog.checkpointAndCleanUpDeltaLog(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.$anonfun$checkpoint$2(Checkpoints.scala:325)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)",
  "schedulingPool" : "default",
  "rddIds" : [ 1318, 1316, 1304, 1303, 1301, 1302, 1300, 1306, 1317, 1305 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 364,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1299, 1295, 1298, 1297, 1294, 1293, 1296 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 363,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:56:56.195GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:56:56.203GMT",
  "completionTime" : "2022-12-20T20:56:56.252GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9905793,
  "executorRunTime" : 24,
  "executorCpuTime" : 23981661,
  "resultSize" : 4236,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 11203,
  "inputRecords" : 32,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 19154,
  "shuffleWriteTime" : 399409,
  "shuffleWriteRecords" : 32,
  "name" : "execute at CheckpointsEdge.scala:309",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$2(CheckpointsEdge.scala:309)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.withDmqTag(CheckpointsEdge.scala:177)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$1(CheckpointsEdge.scala:193)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.writeCheckpoint(CheckpointsEdge.scala:193)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles(CheckpointsEdge.scala:173)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles$(CheckpointsEdge.scala:171)\ncom.databricks.sql.transaction.tahoe.DeltaLog.writeCheckpointFiles(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog(Checkpoints.scala:357)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog$(Checkpoints.scala:351)\ncom.databricks.sql.transaction.tahoe.DeltaLog.checkpointAndCleanUpDeltaLog(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.$anonfun$checkpoint$2(Checkpoints.scala:325)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1318, 1316, 1304, 1303, 1301, 1302, 1300, 1306, 1317, 1305 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 362,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1299, 1295, 1298, 1297, 1294, 1293, 1296 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 361,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:56:55.777GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:56:55.792GMT",
  "completionTime" : "2022-12-20T20:56:55.834GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8059544,
  "executorRunTime" : 17,
  "executorCpuTime" : 16685876,
  "resultSize" : 7114,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1311, 1310 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 360,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 1309, 1304, 1303, 1301, 1308, 1302, 1300, 1306, 1307, 1305 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 359,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1299, 1295, 1298, 1297, 1294, 1293, 1296 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 358,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:56:55.687GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:56:55.714GMT",
  "completionTime" : "2022-12-20T20:56:55.765GMT",
  "executorDeserializeTime" : 10,
  "executorDeserializeCpuTime" : 10442576,
  "executorRunTime" : 23,
  "executorCpuTime" : 19882845,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 9,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 22083,
  "shuffleReadBytes" : 22083,
  "shuffleReadRecords" : 42,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 353407,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1309, 1304, 1303, 1301, 1308, 1302, 1300, 1306, 1307, 1305 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 357,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1299, 1295, 1298, 1297, 1294, 1293, 1296 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 356,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:56:55.494GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:56:55.504GMT",
  "completionTime" : "2022-12-20T20:56:55.592GMT",
  "executorDeserializeTime" : 31,
  "executorDeserializeCpuTime" : 28534366,
  "executorRunTime" : 87,
  "executorCpuTime" : 20335895,
  "resultSize" : 26732,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 85691,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 22083,
  "shuffleWriteTime" : 3558483,
  "shuffleWriteRecords" : 42,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1299, 1295, 1298, 1297, 1294, 1293, 1296 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 355,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:56:55.149GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:56:55.156GMT",
  "completionTime" : "2022-12-20T20:56:55.230GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2962500,
  "executorRunTime" : 57,
  "executorCpuTime" : 3000059,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70449,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1292, 1291, 1290 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 354,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:56:54.488GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:56:54.498GMT",
  "completionTime" : "2022-12-20T20:56:54.754GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7677895,
  "executorRunTime" : 233,
  "executorCpuTime" : 106250644,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12122,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1289 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 353,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 1287, 1281, 1282, 1286, 1280, 1279, 1283, 1284 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 352,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:56:54.439GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:56:54.442GMT",
  "completionTime" : "2022-12-20T20:56:54.472GMT",
  "executorDeserializeTime" : 14,
  "executorDeserializeCpuTime" : 17161789,
  "executorRunTime" : 64,
  "executorCpuTime" : 30952516,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4227,
  "shuffleWriteTime" : 243708,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1287, 1281, 1282, 1286, 1280, 1279, 1283, 1284 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 351,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:55:56.480GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:55:56.493GMT",
  "completionTime" : "2022-12-20T20:55:56.535GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7391720,
  "executorRunTime" : 18,
  "executorCpuTime" : 16070801,
  "resultSize" : 7115,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1274, 1273 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 350,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 1272, 1263, 1265, 1267, 1264, 1268, 1270, 1271, 1266, 1269 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 349,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1262, 1257, 1261, 1258, 1256, 1260, 1259 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 348,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:55:56.384GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:55:56.419GMT",
  "completionTime" : "2022-12-20T20:55:56.470GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7984554,
  "executorRunTime" : 27,
  "executorCpuTime" : 19962949,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 9,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 21733,
  "shuffleReadBytes" : 21733,
  "shuffleReadRecords" : 40,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 384708,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1272, 1263, 1265, 1267, 1264, 1268, 1270, 1271, 1266, 1269 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 347,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1262, 1257, 1261, 1258, 1256, 1260, 1259 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 346,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:55:56.092GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:55:56.100GMT",
  "completionTime" : "2022-12-20T20:55:56.190GMT",
  "executorDeserializeTime" : 24,
  "executorDeserializeCpuTime" : 27675992,
  "executorRunTime" : 95,
  "executorCpuTime" : 19135587,
  "resultSize" : 26732,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 85691,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 21733,
  "shuffleWriteTime" : 12189551,
  "shuffleWriteRecords" : 40,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1262, 1257, 1261, 1258, 1256, 1260, 1259 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 345,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:55:55.651GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:55:55.656GMT",
  "completionTime" : "2022-12-20T20:55:55.738GMT",
  "executorDeserializeTime" : 4,
  "executorDeserializeCpuTime" : 4066877,
  "executorRunTime" : 60,
  "executorCpuTime" : 2980477,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70449,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1255, 1254, 1253 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 344,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:55:54.881GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:55:54.889GMT",
  "completionTime" : "2022-12-20T20:55:55.139GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9397908,
  "executorRunTime" : 224,
  "executorCpuTime" : 107412348,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12127,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1252 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 343,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 1250, 1245, 1242, 1246, 1247, 1249, 1243, 1244 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 342,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:55:54.836GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:55:54.838GMT",
  "completionTime" : "2022-12-20T20:55:54.866GMT",
  "executorDeserializeTime" : 15,
  "executorDeserializeCpuTime" : 17290334,
  "executorRunTime" : 47,
  "executorCpuTime" : 28750376,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4231,
  "shuffleWriteTime" : 202803,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1250, 1245, 1242, 1246, 1247, 1249, 1243, 1244 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 341,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:54:55.733GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:54:55.746GMT",
  "completionTime" : "2022-12-20T20:54:55.789GMT",
  "executorDeserializeTime" : 10,
  "executorDeserializeCpuTime" : 10200459,
  "executorRunTime" : 18,
  "executorCpuTime" : 16799309,
  "resultSize" : 7114,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1237, 1236 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 340,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 1235, 1230, 1232, 1234, 1233, 1229, 1231, 1227, 1226, 1228 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 339,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1225, 1224, 1221, 1220, 1222, 1219, 1223 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 338,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:54:55.646GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:54:55.673GMT",
  "completionTime" : "2022-12-20T20:54:55.721GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7230446,
  "executorRunTime" : 24,
  "executorCpuTime" : 20459690,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 9,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 21471,
  "shuffleReadBytes" : 21471,
  "shuffleReadRecords" : 38,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 335206,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1235, 1230, 1232, 1234, 1233, 1229, 1231, 1227, 1226, 1228 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 337,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1225, 1224, 1221, 1220, 1222, 1219, 1223 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 336,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:54:55.453GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:54:55.459GMT",
  "completionTime" : "2022-12-20T20:54:55.551GMT",
  "executorDeserializeTime" : 41,
  "executorDeserializeCpuTime" : 29381777,
  "executorRunTime" : 95,
  "executorCpuTime" : 22148241,
  "resultSize" : 26732,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 85691,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 21471,
  "shuffleWriteTime" : 9871493,
  "shuffleWriteRecords" : 38,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1225, 1224, 1221, 1220, 1222, 1219, 1223 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 335,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:54:55.126GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:54:55.131GMT",
  "completionTime" : "2022-12-20T20:54:55.205GMT",
  "executorDeserializeTime" : 3,
  "executorDeserializeCpuTime" : 3073500,
  "executorRunTime" : 57,
  "executorCpuTime" : 2692872,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70449,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1218, 1216, 1217 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 334,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:54:54.470GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:54:54.479GMT",
  "completionTime" : "2022-12-20T20:54:54.729GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7436444,
  "executorRunTime" : 226,
  "executorCpuTime" : 109972174,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12126,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1215 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 333,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 1213, 1207, 1210, 1206, 1212, 1205, 1209, 1208 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 332,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:54:54.429GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:54:54.431GMT",
  "completionTime" : "2022-12-20T20:54:54.456GMT",
  "executorDeserializeTime" : 19,
  "executorDeserializeCpuTime" : 18346702,
  "executorRunTime" : 37,
  "executorCpuTime" : 31036292,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4227,
  "shuffleWriteTime" : 201302,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1213, 1207, 1210, 1206, 1212, 1205, 1209, 1208 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 331,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:53:55.740GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:53:55.752GMT",
  "completionTime" : "2022-12-20T20:53:55.795GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8348918,
  "executorRunTime" : 19,
  "executorCpuTime" : 18051630,
  "resultSize" : 7115,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1200, 1199 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 330,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 1198, 1191, 1192, 1194, 1197, 1195, 1189, 1190, 1196, 1193 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 329,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1188, 1186, 1182, 1185, 1184, 1183, 1187 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 328,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:53:55.657GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:53:55.685GMT",
  "completionTime" : "2022-12-20T20:53:55.731GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7417254,
  "executorRunTime" : 22,
  "executorCpuTime" : 19412418,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 9,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 19885,
  "shuffleReadBytes" : 19885,
  "shuffleReadRecords" : 36,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 343007,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1198, 1191, 1192, 1194, 1197, 1195, 1189, 1190, 1196, 1193 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 327,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1188, 1186, 1182, 1185, 1184, 1183, 1187 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 326,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:53:55.469GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:53:55.476GMT",
  "completionTime" : "2022-12-20T20:53:55.561GMT",
  "executorDeserializeTime" : 30,
  "executorDeserializeCpuTime" : 29121349,
  "executorRunTime" : 77,
  "executorCpuTime" : 19333535,
  "resultSize" : 26732,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 85691,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 19885,
  "shuffleWriteTime" : 4052981,
  "shuffleWriteRecords" : 36,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1188, 1186, 1182, 1185, 1184, 1183, 1187 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 325,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:53:55.123GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:53:55.128GMT",
  "completionTime" : "2022-12-20T20:53:55.202GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2778000,
  "executorRunTime" : 55,
  "executorCpuTime" : 2666494,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70449,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1181, 1180, 1179 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 324,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:53:54.481GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:53:54.491GMT",
  "completionTime" : "2022-12-20T20:53:54.738GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9984530,
  "executorRunTime" : 221,
  "executorCpuTime" : 105797293,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12124,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1178 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 323,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 1176, 1171, 1170, 1168, 1172, 1169, 1175, 1173 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 322,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:53:54.439GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:53:54.441GMT",
  "completionTime" : "2022-12-20T20:53:54.466GMT",
  "executorDeserializeTime" : 13,
  "executorDeserializeCpuTime" : 15461392,
  "executorRunTime" : 41,
  "executorCpuTime" : 30677608,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4232,
  "shuffleWriteTime" : 220801,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1176, 1171, 1170, 1168, 1172, 1169, 1175, 1173 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 321,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:52:56.489GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:52:56.510GMT",
  "completionTime" : "2022-12-20T20:52:56.553GMT",
  "executorDeserializeTime" : 10,
  "executorDeserializeCpuTime" : 10385438,
  "executorRunTime" : 16,
  "executorCpuTime" : 15542599,
  "resultSize" : 7112,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1163, 1162 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 320,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 1161, 1154, 1159, 1158, 1153, 1156, 1157, 1160, 1155, 1152 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 319,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1151, 1146, 1149, 1147, 1150, 1148, 1145 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 318,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:52:56.383GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:52:56.426GMT",
  "completionTime" : "2022-12-20T20:52:56.475GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7256273,
  "executorRunTime" : 23,
  "executorCpuTime" : 19918567,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 9,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 18304,
  "shuffleReadBytes" : 18304,
  "shuffleReadRecords" : 34,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 343407,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1161, 1154, 1159, 1158, 1153, 1156, 1157, 1160, 1155, 1152 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 317,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1151, 1146, 1149, 1147, 1150, 1148, 1145 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 316,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:52:56.061GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:52:56.070GMT",
  "completionTime" : "2022-12-20T20:52:56.184GMT",
  "executorDeserializeTime" : 56,
  "executorDeserializeCpuTime" : 29579905,
  "executorRunTime" : 253,
  "executorCpuTime" : 20282672,
  "resultSize" : 26960,
  "jvmGcTime" : 144,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 85691,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 18304,
  "shuffleWriteTime" : 4389578,
  "shuffleWriteRecords" : 34,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1151, 1146, 1149, 1147, 1150, 1148, 1145 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 315,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:52:55.617GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:52:55.623GMT",
  "completionTime" : "2022-12-20T20:52:55.697GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2465547,
  "executorRunTime" : 55,
  "executorCpuTime" : 2444044,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70449,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1144, 1143, 1142 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 314,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:52:54.888GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:52:54.897GMT",
  "completionTime" : "2022-12-20T20:52:55.146GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9777859,
  "executorRunTime" : 223,
  "executorCpuTime" : 108183537,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12123,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1141 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 313,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 1139, 1138, 1136, 1133, 1132, 1131, 1135, 1134 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 312,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:52:54.840GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:52:54.842GMT",
  "completionTime" : "2022-12-20T20:52:54.872GMT",
  "executorDeserializeTime" : 15,
  "executorDeserializeCpuTime" : 15783362,
  "executorRunTime" : 44,
  "executorCpuTime" : 31413847,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4225,
  "shuffleWriteTime" : 221903,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1139, 1138, 1136, 1133, 1132, 1131, 1135, 1134 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 311,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:51:55.747GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:51:55.758GMT",
  "completionTime" : "2022-12-20T20:51:55.800GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9588682,
  "executorRunTime" : 17,
  "executorCpuTime" : 16608498,
  "resultSize" : 7114,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1126, 1125 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 310,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 1124, 1117, 1121, 1119, 1123, 1118, 1116, 1122, 1115, 1120 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 309,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1114, 1108, 1111, 1113, 1109, 1110, 1112 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 308,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:51:55.660GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:51:55.688GMT",
  "completionTime" : "2022-12-20T20:51:55.736GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9491734,
  "executorRunTime" : 23,
  "executorCpuTime" : 19826254,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 9,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 16724,
  "shuffleReadBytes" : 16724,
  "shuffleReadRecords" : 32,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 410710,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1124, 1117, 1121, 1119, 1123, 1118, 1116, 1122, 1115, 1120 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 307,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1114, 1108, 1111, 1113, 1109, 1110, 1112 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 306,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:51:55.472GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:51:55.478GMT",
  "completionTime" : "2022-12-20T20:51:55.566GMT",
  "executorDeserializeTime" : 32,
  "executorDeserializeCpuTime" : 30268172,
  "executorRunTime" : 85,
  "executorCpuTime" : 21348134,
  "resultSize" : 26732,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 85691,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 16724,
  "shuffleWriteTime" : 3751497,
  "shuffleWriteRecords" : 32,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1114, 1108, 1111, 1113, 1109, 1110, 1112 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 305,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:51:55.149GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:51:55.153GMT",
  "completionTime" : "2022-12-20T20:51:55.226GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2936690,
  "executorRunTime" : 54,
  "executorCpuTime" : 2600960,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70449,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1107, 1106, 1105 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 304,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:51:54.490GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:51:54.499GMT",
  "completionTime" : "2022-12-20T20:51:54.745GMT",
  "executorDeserializeTime" : 10,
  "executorDeserializeCpuTime" : 10159842,
  "executorRunTime" : 219,
  "executorCpuTime" : 104048080,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12163,
  "outputRecords" : 9,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1104 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 303,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 1102, 1097, 1101, 1096, 1098, 1095, 1094, 1099 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 302,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:51:54.443GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:51:54.445GMT",
  "completionTime" : "2022-12-20T20:51:54.474GMT",
  "executorDeserializeTime" : 24,
  "executorDeserializeCpuTime" : 17978372,
  "executorRunTime" : 46,
  "executorCpuTime" : 33830242,
  "resultSize" : 26064,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 268697600,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4872,
  "shuffleWriteTime" : 264406,
  "shuffleWriteRecords" : 9,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1102, 1097, 1101, 1096, 1098, 1095, 1094, 1099 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 301,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:51:06.330GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:51:06.388GMT",
  "completionTime" : "2022-12-20T20:51:06.442GMT",
  "executorDeserializeTime" : 6,
  "executorDeserializeCpuTime" : 6237557,
  "executorRunTime" : 32,
  "executorCpuTime" : 32774593,
  "resultSize" : 3578,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at EventLogSparkSQL.scala:96",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.pipelines.execution.core.log.EventLogSparkSQL$.$anonfun$toProto$1(EventLogSparkSQL.scala:96)\ncom.databricks.pipelines.util.SparkSessionUtils$.withSQLConf(SparkSessionUtils.scala:19)\ncom.databricks.pipelines.execution.core.log.EventLogSparkSQL$.toProto(EventLogSparkSQL.scala:96)\ncom.databricks.pipelines.execution.core.log.DataPlaneInstanceEventReader.$anonfun$fetchEventsFromDelta$2(DataPlaneInstanceEventReader.scala:147)\ncom.databricks.pipelines.execution.core.monitoring.DeltaPipelinesUsageLogging.$anonfun$recordPipelinesOperation$2(DeltaPipelinesUsageLogging.scala:105)\ncom.databricks.pipelines.execution.core.monitoring.DeltaPipelinesUsageLogging.$anonfun$recordPipelinesOperation$5(DeltaPipelinesUsageLogging.scala:125)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)\ncom.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:507)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:528)\ncom.databricks.logging.Log4jUsageLoggingShim$.$anonfun$withAttributionContext$1(Log4jUsageLoggingShim.scala:32)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\ncom.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:94)\ncom.databricks.logging.Log4jUsageLoggingShim$.withAttributionContext(Log4jUsageLoggingShim.scala:30)\ncom.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:283)\ncom.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:282)\ncom.databricks.pipelines.execution.core.monitoring.PublicLogging.withAttributionContext(DeltaPipelinesUsageLogging.scala:24)\ncom.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:318)\ncom.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:303)\ncom.databricks.pipelines.execution.core.monitoring.PublicLogging.withAttributionTags(DeltaPipelinesUsageLogging.scala:24)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 1093, 1092, 1091, 1090 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 300,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:51:06.055GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:51:06.066GMT",
  "completionTime" : "2022-12-20T20:51:06.192GMT",
  "executorDeserializeTime" : 3,
  "executorDeserializeCpuTime" : 3986189,
  "executorRunTime" : 105,
  "executorCpuTime" : 63454542,
  "resultSize" : 10962,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 85598,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "executeCollect at OptimizeLocalUnion.scala:71",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:399)\ncom.databricks.sql.execution.UnionWithLocalDataExec.executeCollect(OptimizeLocalUnion.scala:71)\ncom.databricks.sql.transaction.tahoe.util.DatasetRefCache$.$anonfun$getLocalRelation$1(DatasetRefCache.scala:67)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.util.DatasetRefCache$.getLocalRelation(DatasetRefCache.scala:65)\ncom.databricks.sql.transaction.tahoe.stats.SmallTableCache.localRelationCacheEntry$1(SmallTableCache.scala:104)\ncom.databricks.sql.transaction.tahoe.stats.SmallTableCache.$anonfun$withStatsUsingSmallTableCache$7(SmallTableCache.scala:129)\nscala.Option.getOrElse(Option.scala:189)\ncom.databricks.sql.transaction.tahoe.stats.SmallTableCache.$anonfun$withStatsUsingSmallTableCache$6(SmallTableCache.scala:129)\ncom.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724)\ncom.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522)\ncom.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315)\ncom.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278)\ncom.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193)\ncom.google.common.cache.LocalCache.get(LocalCache.java:3932)\ncom.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721)\ncom.databricks.sql.transaction.tahoe.stats.SmallTableCache.$anonfun$withStatsUsingSmallTableCache$1(SmallTableCache.scala:125)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 1086, 1084, 1082, 1081, 1080, 1085, 1083 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 299,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:50:56.269GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:50:56.280GMT",
  "completionTime" : "2022-12-20T20:50:56.323GMT",
  "executorDeserializeTime" : 10,
  "executorDeserializeCpuTime" : 10151276,
  "executorRunTime" : 18,
  "executorCpuTime" : 16999877,
  "resultSize" : 7120,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 858,
  "shuffleReadBytes" : 858,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1075, 1074 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 298,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 1073, 1067, 1071, 1072, 1065, 1069, 1070, 1068, 1066, 1064 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 297,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1063, 1059, 1058, 1057, 1061, 1060, 1062 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 296,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:50:56.182GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:50:56.211GMT",
  "completionTime" : "2022-12-20T20:50:56.258GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 8998576,
  "executorRunTime" : 22,
  "executorCpuTime" : 19436029,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 9,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 15144,
  "shuffleReadBytes" : 15144,
  "shuffleReadRecords" : 30,
  "shuffleWriteBytes" : 858,
  "shuffleWriteTime" : 352110,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1073, 1067, 1071, 1072, 1065, 1069, 1070, 1068, 1066, 1064 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 295,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1063, 1059, 1058, 1057, 1061, 1060, 1062 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 294,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:50:55.988GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:50:55.996GMT",
  "completionTime" : "2022-12-20T20:50:56.086GMT",
  "executorDeserializeTime" : 38,
  "executorDeserializeCpuTime" : 29754383,
  "executorRunTime" : 79,
  "executorCpuTime" : 22475365,
  "resultSize" : 26732,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 85691,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 15144,
  "shuffleWriteTime" : 3599895,
  "shuffleWriteRecords" : 30,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1063, 1059, 1058, 1057, 1061, 1060, 1062 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 293,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:50:55.630GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:50:55.634GMT",
  "completionTime" : "2022-12-20T20:50:55.713GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2564500,
  "executorRunTime" : 62,
  "executorCpuTime" : 2388496,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70449,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1056, 1055, 1054 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 292,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:50:54.907GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:50:54.915GMT",
  "completionTime" : "2022-12-20T20:50:55.162GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7050518,
  "executorRunTime" : 221,
  "executorCpuTime" : 105821333,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12170,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1053 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 291,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 1051, 1045, 1044, 1047, 1046, 1048, 1043, 1050 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 290,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:50:54.864GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:50:54.866GMT",
  "completionTime" : "2022-12-20T20:50:54.892GMT",
  "executorDeserializeTime" : 20,
  "executorDeserializeCpuTime" : 17891250,
  "executorRunTime" : 42,
  "executorCpuTime" : 32373839,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4254,
  "shuffleWriteTime" : 225904,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1051, 1045, 1044, 1047, 1046, 1048, 1043, 1050 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 289,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:49:56.041GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:49:56.061GMT",
  "completionTime" : "2022-12-20T20:49:56.102GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7863206,
  "executorRunTime" : 17,
  "executorCpuTime" : 16200114,
  "resultSize" : 7118,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1038, 1037 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 288,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 1036, 1032, 1035, 1031, 1034, 1033, 1029, 1030, 1028, 1027 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 287,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1026, 1022, 1020, 1025, 1021, 1024, 1023 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 286,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:49:55.943GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:49:55.984GMT",
  "completionTime" : "2022-12-20T20:49:56.031GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7333948,
  "executorRunTime" : 23,
  "executorCpuTime" : 21007136,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 7,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 13415,
  "shuffleReadBytes" : 13415,
  "shuffleReadRecords" : 28,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 333509,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1036, 1032, 1035, 1031, 1034, 1033, 1029, 1030, 1028, 1027 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 285,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 1026, 1022, 1020, 1025, 1021, 1024, 1023 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 284,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:49:55.642GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:49:55.649GMT",
  "completionTime" : "2022-12-20T20:49:55.740GMT",
  "executorDeserializeTime" : 20,
  "executorDeserializeCpuTime" : 22964632,
  "executorRunTime" : 92,
  "executorCpuTime" : 18798833,
  "resultSize" : 20876,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 85691,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 13415,
  "shuffleWriteTime" : 2636471,
  "shuffleWriteRecords" : 28,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1026, 1022, 1020, 1025, 1021, 1024, 1023 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 283,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:49:55.112GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:49:55.118GMT",
  "completionTime" : "2022-12-20T20:49:55.190GMT",
  "executorDeserializeTime" : 3,
  "executorDeserializeCpuTime" : 3128415,
  "executorRunTime" : 53,
  "executorCpuTime" : 3179247,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70449,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1019, 1018, 1017 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 282,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:49:54.474GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:49:54.485GMT",
  "completionTime" : "2022-12-20T20:49:54.731GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8772670,
  "executorRunTime" : 222,
  "executorCpuTime" : 113489442,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12130,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1016 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 281,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 1014, 1011, 1013, 1009, 1010, 1007, 1008, 1006 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 280,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:49:54.428GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:49:54.431GMT",
  "completionTime" : "2022-12-20T20:49:54.459GMT",
  "executorDeserializeTime" : 21,
  "executorDeserializeCpuTime" : 17378872,
  "executorRunTime" : 38,
  "executorCpuTime" : 31384021,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4232,
  "shuffleWriteTime" : 266707,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1014, 1011, 1013, 1009, 1010, 1007, 1008, 1006 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 279,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:48:55.728GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:48:55.739GMT",
  "completionTime" : "2022-12-20T20:48:55.783GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9282664,
  "executorRunTime" : 18,
  "executorCpuTime" : 16691982,
  "resultSize" : 7117,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 1001, 1000 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 278,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 999, 994, 997, 998, 991, 996, 990, 993, 995, 992 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 277,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 989, 988, 985, 986, 987, 983, 984 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 276,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:48:55.640GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:48:55.665GMT",
  "completionTime" : "2022-12-20T20:48:55.714GMT",
  "executorDeserializeTime" : 11,
  "executorDeserializeCpuTime" : 11240127,
  "executorRunTime" : 22,
  "executorCpuTime" : 19067380,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 5,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 11692,
  "shuffleReadBytes" : 11692,
  "shuffleReadRecords" : 26,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 332910,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 999, 994, 997, 998, 991, 996, 990, 993, 995, 992 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 275,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 989, 988, 985, 986, 987, 983, 984 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 274,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 5,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 5,
  "submissionTime" : "2022-12-20T20:48:55.444GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:48:55.451GMT",
  "completionTime" : "2022-12-20T20:48:55.544GMT",
  "executorDeserializeTime" : 23,
  "executorDeserializeCpuTime" : 19246416,
  "executorRunTime" : 79,
  "executorCpuTime" : 15006901,
  "resultSize" : 15020,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 85691,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 11692,
  "shuffleWriteTime" : 1695444,
  "shuffleWriteRecords" : 26,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 989, 988, 985, 986, 987, 983, 984 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 273,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:48:55.106GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:48:55.110GMT",
  "completionTime" : "2022-12-20T20:48:55.192GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2479777,
  "executorRunTime" : 62,
  "executorCpuTime" : 2418631,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70449,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 982, 980, 981 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 272,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:48:54.489GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:48:54.498GMT",
  "completionTime" : "2022-12-20T20:48:54.750GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7374732,
  "executorRunTime" : 230,
  "executorCpuTime" : 107670137,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12151,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 979 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 271,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 977, 970, 971, 976, 973, 972, 969, 974 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 270,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:48:54.442GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:48:54.445GMT",
  "completionTime" : "2022-12-20T20:48:54.475GMT",
  "executorDeserializeTime" : 18,
  "executorDeserializeCpuTime" : 17731585,
  "executorRunTime" : 48,
  "executorCpuTime" : 37030137,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4234,
  "shuffleWriteTime" : 207407,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 977, 970, 971, 976, 973, 972, 969, 974 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 269,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:47:55.938GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:47:55.951GMT",
  "completionTime" : "2022-12-20T20:47:55.990GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7058101,
  "executorRunTime" : 17,
  "executorCpuTime" : 16493597,
  "resultSize" : 7122,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 964, 963 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 268,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 962, 959, 957, 955, 956, 961, 954, 958, 960, 953 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 267,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 952, 948, 951, 947, 950, 949, 946 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 266,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:47:55.854GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:47:55.883GMT",
  "completionTime" : "2022-12-20T20:47:55.927GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7293588,
  "executorRunTime" : 21,
  "executorCpuTime" : 19219514,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 3,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 9965,
  "shuffleReadBytes" : 9965,
  "shuffleReadRecords" : 24,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 341609,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 962, 959, 957, 955, 956, 961, 954, 958, 960, 953 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 265,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 952, 948, 951, 947, 950, 949, 946 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 264,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 3,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 3,
  "submissionTime" : "2022-12-20T20:47:55.650GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:47:55.658GMT",
  "completionTime" : "2022-12-20T20:47:55.755GMT",
  "executorDeserializeTime" : 11,
  "executorDeserializeCpuTime" : 11124633,
  "executorRunTime" : 80,
  "executorCpuTime" : 61146888,
  "resultSize" : 9164,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 85691,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 9965,
  "shuffleWriteTime" : 1137030,
  "shuffleWriteRecords" : 24,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 952, 948, 951, 947, 950, 949, 946 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 263,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:47:55.210GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:47:55.218GMT",
  "completionTime" : "2022-12-20T20:47:55.296GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2471577,
  "executorRunTime" : 58,
  "executorCpuTime" : 2642563,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70449,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 945, 943, 944 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 262,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:47:54.527GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:47:54.536GMT",
  "completionTime" : "2022-12-20T20:47:54.791GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8256723,
  "executorRunTime" : 227,
  "executorCpuTime" : 114215549,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12163,
  "outputRecords" : 9,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 942 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 261,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 940, 934, 939, 936, 935, 932, 933, 937 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 260,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:47:54.479GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:47:54.481GMT",
  "completionTime" : "2022-12-20T20:47:54.510GMT",
  "executorDeserializeTime" : 29,
  "executorDeserializeCpuTime" : 20994694,
  "executorRunTime" : 49,
  "executorCpuTime" : 36837226,
  "resultSize" : 26064,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 268697600,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4863,
  "shuffleWriteTime" : 250210,
  "shuffleWriteRecords" : 9,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 940, 934, 939, 936, 935, 932, 933, 937 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 259,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:46:56.996GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:46:57.012GMT",
  "completionTime" : "2022-12-20T20:46:57.158GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9335080,
  "executorRunTime" : 119,
  "executorCpuTime" : 50189619,
  "resultSize" : 5397,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 15128,
  "shuffleReadBytes" : 15128,
  "shuffleReadRecords" : 22,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at CheckpointsEdge.scala:313",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.rdd.RDD.collect(RDD.scala:1025)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$2(CheckpointsEdge.scala:313)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.withDmqTag(CheckpointsEdge.scala:177)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$1(CheckpointsEdge.scala:193)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.writeCheckpoint(CheckpointsEdge.scala:193)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles(CheckpointsEdge.scala:173)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles$(CheckpointsEdge.scala:171)\ncom.databricks.sql.transaction.tahoe.DeltaLog.writeCheckpointFiles(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog(Checkpoints.scala:357)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog$(Checkpoints.scala:351)\ncom.databricks.sql.transaction.tahoe.DeltaLog.checkpointAndCleanUpDeltaLog(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.$anonfun$checkpoint$2(Checkpoints.scala:325)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 931, 930, 929 ],
  "accumulatorUpdates" : [ {
    "id" : 9401,
    "name" : "checkpointSizeRows",
    "value" : "22"
  }, {
    "id" : 9404,
    "name" : "checkpointSizeInBytes",
    "value" : "53741"
  }, {
    "id" : 9402,
    "name" : "numOfFiles",
    "value" : "20"
  } ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 3032681080,
    "JVMOffHeapMemory" : 243350384,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 6624710,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 6624710,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 18624975,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 213,
    "MinorGCTime" : 3494,
    "MajorGCCount" : 14,
    "MajorGCTime" : 2236,
    "TotalGCTime" : 5730
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 258,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at CheckpointsEdge.scala:309",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$2(CheckpointsEdge.scala:309)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.withDmqTag(CheckpointsEdge.scala:177)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$1(CheckpointsEdge.scala:193)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.writeCheckpoint(CheckpointsEdge.scala:193)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles(CheckpointsEdge.scala:173)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles$(CheckpointsEdge.scala:171)\ncom.databricks.sql.transaction.tahoe.DeltaLog.writeCheckpointFiles(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog(Checkpoints.scala:357)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog$(Checkpoints.scala:351)\ncom.databricks.sql.transaction.tahoe.DeltaLog.checkpointAndCleanUpDeltaLog(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.$anonfun$checkpoint$2(Checkpoints.scala:325)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)",
  "schedulingPool" : "default",
  "rddIds" : [ 928, 914, 912, 913, 910, 915, 916, 911, 926, 927 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 257,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 909, 903, 904, 905, 908, 906, 907 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 256,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:46:56.917GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:46:56.928GMT",
  "completionTime" : "2022-12-20T20:46:56.979GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9989181,
  "executorRunTime" : 23,
  "executorCpuTime" : 23943306,
  "resultSize" : 4236,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 8572,
  "inputRecords" : 22,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 15128,
  "shuffleWriteTime" : 407483,
  "shuffleWriteRecords" : 22,
  "name" : "execute at CheckpointsEdge.scala:309",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$2(CheckpointsEdge.scala:309)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.withDmqTag(CheckpointsEdge.scala:177)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$1(CheckpointsEdge.scala:193)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.writeCheckpoint(CheckpointsEdge.scala:193)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles(CheckpointsEdge.scala:173)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles$(CheckpointsEdge.scala:171)\ncom.databricks.sql.transaction.tahoe.DeltaLog.writeCheckpointFiles(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog(Checkpoints.scala:357)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog$(Checkpoints.scala:351)\ncom.databricks.sql.transaction.tahoe.DeltaLog.checkpointAndCleanUpDeltaLog(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.$anonfun$checkpoint$2(Checkpoints.scala:325)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 928, 914, 912, 913, 910, 915, 916, 911, 926, 927 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 255,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 909, 903, 904, 905, 908, 906, 907 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 254,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:46:56.464GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:46:56.478GMT",
  "completionTime" : "2022-12-20T20:46:56.520GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7981307,
  "executorRunTime" : 18,
  "executorCpuTime" : 16669162,
  "resultSize" : 7117,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 921, 920 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 253,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 919, 914, 912, 913, 918, 917, 910, 915, 916, 911 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 252,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 909, 903, 904, 905, 908, 906, 907 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 251,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:46:56.368GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:46:56.404GMT",
  "completionTime" : "2022-12-20T20:46:56.454GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8613323,
  "executorRunTime" : 24,
  "executorCpuTime" : 22116360,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 9,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 18712,
  "shuffleReadBytes" : 18712,
  "shuffleReadRecords" : 32,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 324708,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 919, 914, 912, 913, 918, 917, 910, 915, 916, 911 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 250,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 909, 903, 904, 905, 908, 906, 907 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 249,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:46:56.065GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:46:56.073GMT",
  "completionTime" : "2022-12-20T20:46:56.166GMT",
  "executorDeserializeTime" : 27,
  "executorDeserializeCpuTime" : 29311266,
  "executorRunTime" : 110,
  "executorCpuTime" : 22989684,
  "resultSize" : 26732,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 82739,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 18712,
  "shuffleWriteTime" : 3044584,
  "shuffleWriteRecords" : 32,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 909, 903, 904, 905, 908, 906, 907 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 248,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:46:55.118GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:46:55.123GMT",
  "completionTime" : "2022-12-20T20:46:55.197GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2155700,
  "executorRunTime" : 58,
  "executorCpuTime" : 2658189,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70637,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 902, 901, 900 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 247,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:46:54.479GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:46:54.488GMT",
  "completionTime" : "2022-12-20T20:46:54.730GMT",
  "executorDeserializeTime" : 10,
  "executorDeserializeCpuTime" : 10290495,
  "executorRunTime" : 216,
  "executorCpuTime" : 109957896,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12168,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 899 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 246,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 897, 892, 891, 889, 896, 894, 890, 893 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 245,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:46:54.436GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:46:54.438GMT",
  "completionTime" : "2022-12-20T20:46:54.464GMT",
  "executorDeserializeTime" : 15,
  "executorDeserializeCpuTime" : 16876745,
  "executorRunTime" : 42,
  "executorCpuTime" : 32312351,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4254,
  "shuffleWriteTime" : 216604,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 897, 892, 891, 889, 896, 894, 890, 893 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 244,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:45:56.030GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:45:56.044GMT",
  "completionTime" : "2022-12-20T20:45:56.087GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7522221,
  "executorRunTime" : 18,
  "executorCpuTime" : 16884009,
  "resultSize" : 7118,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 884, 883 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 243,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 882, 877, 876, 879, 874, 875, 880, 878, 873, 881 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 242,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 872, 869, 866, 868, 870, 871, 867 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 241,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:45:55.937GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:45:55.967GMT",
  "completionTime" : "2022-12-20T20:45:56.018GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8188513,
  "executorRunTime" : 23,
  "executorCpuTime" : 20109445,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 9,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 18274,
  "shuffleReadBytes" : 18274,
  "shuffleReadRecords" : 30,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 397812,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 882, 877, 876, 879, 874, 875, 880, 878, 873, 881 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 240,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 872, 869, 866, 868, 870, 871, 867 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 239,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:45:55.741GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:45:55.748GMT",
  "completionTime" : "2022-12-20T20:45:55.837GMT",
  "executorDeserializeTime" : 28,
  "executorDeserializeCpuTime" : 28724004,
  "executorRunTime" : 87,
  "executorCpuTime" : 22466255,
  "resultSize" : 26732,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 82739,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 18274,
  "shuffleWriteTime" : 3425801,
  "shuffleWriteRecords" : 30,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 872, 869, 866, 868, 870, 871, 867 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 238,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:45:55.413GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:45:55.417GMT",
  "completionTime" : "2022-12-20T20:45:55.489GMT",
  "executorDeserializeTime" : 3,
  "executorDeserializeCpuTime" : 3526433,
  "executorRunTime" : 52,
  "executorCpuTime" : 2896285,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70637,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 865, 863, 864 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 237,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:45:54.501GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:45:54.511GMT",
  "completionTime" : "2022-12-20T20:45:54.777GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9988613,
  "executorRunTime" : 238,
  "executorCpuTime" : 116305279,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12127,
  "outputRecords" : 9,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 862 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 236,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 860, 856, 859, 853, 857, 855, 852, 854 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 235,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:45:54.453GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:45:54.456GMT",
  "completionTime" : "2022-12-20T20:45:54.486GMT",
  "executorDeserializeTime" : 25,
  "executorDeserializeCpuTime" : 18630734,
  "executorRunTime" : 37,
  "executorCpuTime" : 33895044,
  "resultSize" : 26064,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 268697600,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4842,
  "shuffleWriteTime" : 225607,
  "shuffleWriteRecords" : 9,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 860, 856, 859, 853, 857, 855, 852, 854 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 234,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:44:55.832GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:44:55.848GMT",
  "completionTime" : "2022-12-20T20:44:55.900GMT",
  "executorDeserializeTime" : 11,
  "executorDeserializeCpuTime" : 11422623,
  "executorRunTime" : 22,
  "executorCpuTime" : 21009098,
  "resultSize" : 7117,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 847, 846 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 233,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 845, 842, 844, 840, 836, 838, 841, 837, 843, 839 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 232,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 835, 832, 834, 830, 829, 833, 831 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 231,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:44:55.734GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:44:55.770GMT",
  "completionTime" : "2022-12-20T20:44:55.821GMT",
  "executorDeserializeTime" : 10,
  "executorDeserializeCpuTime" : 10607877,
  "executorRunTime" : 23,
  "executorCpuTime" : 21089462,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 9,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 17941,
  "shuffleReadBytes" : 17941,
  "shuffleReadRecords" : 28,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 347208,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 845, 842, 844, 840, 836, 838, 841, 837, 843, 839 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 230,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 835, 832, 834, 830, 829, 833, 831 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 229,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:44:55.526GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:44:55.534GMT",
  "completionTime" : "2022-12-20T20:44:55.639GMT",
  "executorDeserializeTime" : 25,
  "executorDeserializeCpuTime" : 27634143,
  "executorRunTime" : 106,
  "executorCpuTime" : 23768564,
  "resultSize" : 26732,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 82739,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 17941,
  "shuffleWriteTime" : 3443092,
  "shuffleWriteRecords" : 28,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 835, 832, 834, 830, 829, 833, 831 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 228,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:44:55.178GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:44:55.183GMT",
  "completionTime" : "2022-12-20T20:44:55.269GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2225268,
  "executorRunTime" : 68,
  "executorCpuTime" : 2404070,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70637,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 828, 827, 826 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 227,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:44:54.473GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:44:54.482GMT",
  "completionTime" : "2022-12-20T20:44:54.752GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9974332,
  "executorRunTime" : 244,
  "executorCpuTime" : 115541817,
  "resultSize" : 5530,
  "jvmGcTime" : 22,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12185,
  "outputRecords" : 10,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 825 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 226,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 823, 818, 820, 816, 815, 822, 819, 817 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 225,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:44:54.429GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:44:54.432GMT",
  "completionTime" : "2022-12-20T20:44:54.458GMT",
  "executorDeserializeTime" : 23,
  "executorDeserializeCpuTime" : 19509701,
  "executorRunTime" : 52,
  "executorCpuTime" : 37128643,
  "resultSize" : 26064,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 268697600,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4921,
  "shuffleWriteTime" : 239002,
  "shuffleWriteRecords" : 10,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 823, 818, 820, 816, 815, 822, 819, 817 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 224,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:44:26.438GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:44:26.452GMT",
  "completionTime" : "2022-12-20T20:44:26.493GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7690694,
  "executorRunTime" : 19,
  "executorCpuTime" : 18106955,
  "resultSize" : 7119,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 810, 809 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 223,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 808, 807, 803, 801, 804, 802, 805, 806, 800, 799 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 222,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 798, 797, 793, 796, 795, 794, 792 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 221,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:44:26.339GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:44:26.378GMT",
  "completionTime" : "2022-12-20T20:44:26.428GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7983998,
  "executorRunTime" : 25,
  "executorCpuTime" : 21317842,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 9,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 16354,
  "shuffleReadBytes" : 16354,
  "shuffleReadRecords" : 26,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 364510,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 808, 807, 803, 801, 804, 802, 805, 806, 800, 799 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 220,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 798, 797, 793, 796, 795, 794, 792 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 219,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:44:26.033GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:44:26.041GMT",
  "completionTime" : "2022-12-20T20:44:26.143GMT",
  "executorDeserializeTime" : 33,
  "executorDeserializeCpuTime" : 31672139,
  "executorRunTime" : 99,
  "executorCpuTime" : 27388038,
  "resultSize" : 26732,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 82739,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 16354,
  "shuffleWriteTime" : 3545892,
  "shuffleWriteRecords" : 26,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 798, 797, 793, 796, 795, 794, 792 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 218,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:44:25.580GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:44:25.588GMT",
  "completionTime" : "2022-12-20T20:44:25.670GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2118070,
  "executorRunTime" : 64,
  "executorCpuTime" : 2767890,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70637,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 791, 790, 789 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 217,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:44:24.831GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:44:24.843GMT",
  "completionTime" : "2022-12-20T20:44:25.108GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8356976,
  "executorRunTime" : 238,
  "executorCpuTime" : 118240488,
  "resultSize" : 5011,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 11281,
  "outputRecords" : 1,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 788, 781, 784, 782, 786, 783, 785 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 216,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:43:55.792GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:43:55.810GMT",
  "completionTime" : "2022-12-20T20:43:55.852GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7150414,
  "executorRunTime" : 19,
  "executorCpuTime" : 17621915,
  "resultSize" : 7132,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 853,
  "shuffleReadBytes" : 853,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 776, 775 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 215,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 774, 769, 767, 773, 766, 768, 770, 771, 765, 772 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 214,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 764, 759, 758, 760, 761, 762, 763 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 213,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:43:55.697GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:43:55.724GMT",
  "completionTime" : "2022-12-20T20:43:55.777GMT",
  "executorDeserializeTime" : 11,
  "executorDeserializeCpuTime" : 11928420,
  "executorRunTime" : 25,
  "executorCpuTime" : 21701705,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 9,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 14896,
  "shuffleReadBytes" : 14896,
  "shuffleReadRecords" : 24,
  "shuffleWriteBytes" : 853,
  "shuffleWriteTime" : 350205,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 774, 769, 767, 773, 766, 768, 770, 771, 765, 772 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 212,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 764, 759, 758, 760, 761, 762, 763 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 211,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:43:55.501GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:43:55.508GMT",
  "completionTime" : "2022-12-20T20:43:55.596GMT",
  "executorDeserializeTime" : 37,
  "executorDeserializeCpuTime" : 32270444,
  "executorRunTime" : 87,
  "executorCpuTime" : 21739824,
  "resultSize" : 26732,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 82739,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 14896,
  "shuffleWriteTime" : 4471567,
  "shuffleWriteRecords" : 24,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 764, 759, 758, 760, 761, 762, 763 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 210,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:43:55.151GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:43:55.156GMT",
  "completionTime" : "2022-12-20T20:43:55.231GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2368538,
  "executorRunTime" : 58,
  "executorCpuTime" : 2204820,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70637,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 757, 755, 756 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 209,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:43:54.489GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:43:54.499GMT",
  "completionTime" : "2022-12-20T20:43:54.753GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8026399,
  "executorRunTime" : 227,
  "executorCpuTime" : 116683223,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12270,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 754 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 208,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 752, 747, 749, 746, 751, 744, 745, 748 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 207,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:43:54.435GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:43:54.437GMT",
  "completionTime" : "2022-12-20T20:43:54.473GMT",
  "executorDeserializeTime" : 18,
  "executorDeserializeCpuTime" : 18080876,
  "executorRunTime" : 50,
  "executorCpuTime" : 32361575,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4295,
  "shuffleWriteTime" : 200102,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 752, 747, 749, 746, 751, 744, 745, 748 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 206,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:42:55.812GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:42:55.824GMT",
  "completionTime" : "2022-12-20T20:42:55.869GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7537929,
  "executorRunTime" : 19,
  "executorCpuTime" : 17675051,
  "resultSize" : 7119,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 739, 738 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 205,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 737, 736, 733, 731, 735, 734, 728, 729, 730, 732 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 204,
  "attemptId" : 0,
  "numTasks" : 11,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 727, 723, 721, 725, 722, 726, 724 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 203,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:42:55.710GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:42:55.751GMT",
  "completionTime" : "2022-12-20T20:42:55.801GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8795915,
  "executorRunTime" : 24,
  "executorCpuTime" : 21006623,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 11,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 13447,
  "shuffleReadBytes" : 13447,
  "shuffleReadRecords" : 22,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 353310,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 737, 736, 733, 731, 735, 734, 728, 729, 730, 732 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 202,
  "attemptId" : 0,
  "numTasks" : 11,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 727, 723, 721, 725, 722, 726, 724 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 201,
  "attemptId" : 0,
  "numTasks" : 11,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 11,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 11,
  "submissionTime" : "2022-12-20T20:42:55.505GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:42:55.512GMT",
  "completionTime" : "2022-12-20T20:42:55.607GMT",
  "executorDeserializeTime" : 35,
  "executorDeserializeCpuTime" : 32992927,
  "executorRunTime" : 95,
  "executorCpuTime" : 24215495,
  "resultSize" : 32588,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 82739,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 13447,
  "shuffleWriteTime" : 6704176,
  "shuffleWriteRecords" : 22,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 727, 723, 721, 725, 722, 726, 724 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 200,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:42:55.155GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:42:55.160GMT",
  "completionTime" : "2022-12-20T20:42:55.238GMT",
  "executorDeserializeTime" : 3,
  "executorDeserializeCpuTime" : 3107400,
  "executorRunTime" : 58,
  "executorCpuTime" : 2892082,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70637,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 720, 719, 718 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 199,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:42:54.503GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:42:54.512GMT",
  "completionTime" : "2022-12-20T20:42:54.770GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7846377,
  "executorRunTime" : 234,
  "executorCpuTime" : 120577149,
  "resultSize" : 5473,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12035,
  "outputRecords" : 8,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 717 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 198,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 715, 710, 708, 714, 707, 711, 712, 709 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 197,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:42:54.455GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:42:54.457GMT",
  "completionTime" : "2022-12-20T20:42:54.487GMT",
  "executorDeserializeTime" : 19,
  "executorDeserializeCpuTime" : 16957104,
  "executorRunTime" : 61,
  "executorCpuTime" : 36941978,
  "resultSize" : 26064,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 268697600,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4813,
  "shuffleWriteTime" : 226505,
  "shuffleWriteRecords" : 8,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 715, 710, 708, 714, 707, 711, 712, 709 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 196,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:41:56.688GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:41:56.700GMT",
  "completionTime" : "2022-12-20T20:41:56.743GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7578561,
  "executorRunTime" : 20,
  "executorCpuTime" : 18911083,
  "resultSize" : 7123,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 702, 701 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 195,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 700, 691, 699, 696, 694, 695, 698, 697, 693, 692 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 194,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 690, 687, 686, 685, 689, 684, 688 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 193,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:41:56.531GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:41:56.558GMT",
  "completionTime" : "2022-12-20T20:41:56.677GMT",
  "executorDeserializeTime" : 10,
  "executorDeserializeCpuTime" : 10103653,
  "executorRunTime" : 91,
  "executorCpuTime" : 74705264,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 5,
  "shuffleLocalBlocksFetched" : 4,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 9838,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 1859,
  "shuffleReadBytes" : 11697,
  "shuffleReadRecords" : 20,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 366308,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 700, 691, 699, 696, 694, 695, 698, 697, 693, 692 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 192,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 690, 687, 686, 685, 689, 684, 688 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 191,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:41:56.184GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:41:56.191GMT",
  "completionTime" : "2022-12-20T20:41:56.330GMT",
  "executorDeserializeTime" : 35,
  "executorDeserializeCpuTime" : 37303676,
  "executorRunTime" : 143,
  "executorCpuTime" : 92926951,
  "resultSize" : 26732,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 82739,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 11697,
  "shuffleWriteTime" : 6452450,
  "shuffleWriteRecords" : 20,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 690, 687, 686, 685, 689, 684, 688 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 190,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:41:55.709GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:41:55.715GMT",
  "completionTime" : "2022-12-20T20:41:55.822GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2598578,
  "executorRunTime" : 88,
  "executorCpuTime" : 3850568,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70637,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 683, 682, 681 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 189,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:41:54.896GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:41:54.905GMT",
  "completionTime" : "2022-12-20T20:41:55.234GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9229984,
  "executorRunTime" : 301,
  "executorCpuTime" : 178390190,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12182,
  "outputRecords" : 9,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 680 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 188,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 678, 675, 670, 673, 671, 672, 677, 674 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 187,
  "attemptId" : 0,
  "numTasks" : 9,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 9,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 9,
  "submissionTime" : "2022-12-20T20:41:54.833GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:41:54.836GMT",
  "completionTime" : "2022-12-20T20:41:54.879GMT",
  "executorDeserializeTime" : 42,
  "executorDeserializeCpuTime" : 26012333,
  "executorRunTime" : 78,
  "executorCpuTime" : 66171819,
  "resultSize" : 29322,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 302284800,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 5424,
  "shuffleWriteTime" : 296417,
  "shuffleWriteRecords" : 9,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 678, 675, 670, 673, 671, 672, 677, 674 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 186,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:40:56.050GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:40:56.065GMT",
  "completionTime" : "2022-12-20T20:40:56.122GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9237653,
  "executorRunTime" : 26,
  "executorCpuTime" : 24251446,
  "resultSize" : 7122,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 665, 664 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 185,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 663, 662, 656, 655, 654, 659, 661, 658, 657, 660 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 184,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 653, 649, 650, 652, 648, 647, 651 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 183,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:40:55.826GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:40:55.855GMT",
  "completionTime" : "2022-12-20T20:40:56.039GMT",
  "executorDeserializeTime" : 11,
  "executorDeserializeCpuTime" : 9178165,
  "executorRunTime" : 56,
  "executorCpuTime" : 31336174,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 4,
  "shuffleLocalBlocksFetched" : 3,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 8580,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 1398,
  "shuffleReadBytes" : 9978,
  "shuffleReadRecords" : 18,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 573146,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 663, 662, 656, 655, 654, 659, 661, 658, 657, 660 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 182,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 653, 649, 650, 652, 648, 647, 651 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 181,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:40:55.618GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:40:55.624GMT",
  "completionTime" : "2022-12-20T20:40:55.724GMT",
  "executorDeserializeTime" : 26,
  "executorDeserializeCpuTime" : 27219154,
  "executorRunTime" : 89,
  "executorCpuTime" : 23018625,
  "resultSize" : 20876,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 82739,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 9978,
  "shuffleWriteTime" : 3440951,
  "shuffleWriteRecords" : 18,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 653, 649, 650, 652, 648, 647, 651 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 180,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:40:55.201GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:40:55.207GMT",
  "completionTime" : "2022-12-20T20:40:55.335GMT",
  "executorDeserializeTime" : 2,
  "executorDeserializeCpuTime" : 2190256,
  "executorRunTime" : 108,
  "executorCpuTime" : 2337461,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70637,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 646, 644, 645 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 179,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:40:54.489GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:40:54.499GMT",
  "completionTime" : "2022-12-20T20:40:54.835GMT",
  "executorDeserializeTime" : 11,
  "executorDeserializeCpuTime" : 11285552,
  "executorRunTime" : 305,
  "executorCpuTime" : 190264872,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12129,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 643 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 178,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 641, 637, 633, 638, 636, 635, 640, 634 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 177,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:40:54.434GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:40:54.437GMT",
  "completionTime" : "2022-12-20T20:40:54.472GMT",
  "executorDeserializeTime" : 18,
  "executorDeserializeCpuTime" : 21201476,
  "executorRunTime" : 51,
  "executorCpuTime" : 47017655,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4229,
  "shuffleWriteTime" : 238613,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 641, 637, 633, 638, 636, 635, 640, 634 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 176,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:40:46.473GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:40:46.527GMT",
  "completionTime" : "2022-12-20T20:40:46.751GMT",
  "executorDeserializeTime" : 50,
  "executorDeserializeCpuTime" : 50972458,
  "executorRunTime" : 155,
  "executorCpuTime" : 131857652,
  "resultSize" : 3578,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at EventLogSparkSQL.scala:96",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.pipelines.execution.core.log.EventLogSparkSQL$.$anonfun$toProto$1(EventLogSparkSQL.scala:96)\ncom.databricks.pipelines.util.SparkSessionUtils$.withSQLConf(SparkSessionUtils.scala:19)\ncom.databricks.pipelines.execution.core.log.EventLogSparkSQL$.toProto(EventLogSparkSQL.scala:96)\ncom.databricks.pipelines.execution.core.log.DataPlaneInstanceEventReader.$anonfun$fetchEventsFromDelta$2(DataPlaneInstanceEventReader.scala:147)\ncom.databricks.pipelines.execution.core.monitoring.DeltaPipelinesUsageLogging.$anonfun$recordPipelinesOperation$2(DeltaPipelinesUsageLogging.scala:105)\ncom.databricks.pipelines.execution.core.monitoring.DeltaPipelinesUsageLogging.$anonfun$recordPipelinesOperation$5(DeltaPipelinesUsageLogging.scala:125)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)\ncom.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:507)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:528)\ncom.databricks.logging.Log4jUsageLoggingShim$.$anonfun$withAttributionContext$1(Log4jUsageLoggingShim.scala:32)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\ncom.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:94)\ncom.databricks.logging.Log4jUsageLoggingShim$.withAttributionContext(Log4jUsageLoggingShim.scala:30)\ncom.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:283)\ncom.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:282)\ncom.databricks.pipelines.execution.core.monitoring.PublicLogging.withAttributionContext(DeltaPipelinesUsageLogging.scala:24)\ncom.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:318)\ncom.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:303)\ncom.databricks.pipelines.execution.core.monitoring.PublicLogging.withAttributionTags(DeltaPipelinesUsageLogging.scala:24)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 632, 630, 629, 631 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 175,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:40:46.069GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:40:46.086GMT",
  "completionTime" : "2022-12-20T20:40:46.329GMT",
  "executorDeserializeTime" : 5,
  "executorDeserializeCpuTime" : 5336608,
  "executorRunTime" : 222,
  "executorCpuTime" : 90823781,
  "resultSize" : 7624,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 82649,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "executeCollect at OptimizeLocalUnion.scala:71",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:399)\ncom.databricks.sql.execution.UnionWithLocalDataExec.executeCollect(OptimizeLocalUnion.scala:71)\ncom.databricks.sql.transaction.tahoe.util.DatasetRefCache$.$anonfun$getLocalRelation$1(DatasetRefCache.scala:67)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.util.DatasetRefCache$.getLocalRelation(DatasetRefCache.scala:65)\ncom.databricks.sql.transaction.tahoe.stats.SmallTableCache.localRelationCacheEntry$1(SmallTableCache.scala:104)\ncom.databricks.sql.transaction.tahoe.stats.SmallTableCache.$anonfun$withStatsUsingSmallTableCache$7(SmallTableCache.scala:129)\nscala.Option.getOrElse(Option.scala:189)\ncom.databricks.sql.transaction.tahoe.stats.SmallTableCache.$anonfun$withStatsUsingSmallTableCache$6(SmallTableCache.scala:129)\ncom.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724)\ncom.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522)\ncom.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315)\ncom.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278)\ncom.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193)\ncom.google.common.cache.LocalCache.get(LocalCache.java:3932)\ncom.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721)\ncom.databricks.sql.transaction.tahoe.stats.SmallTableCache.$anonfun$withStatsUsingSmallTableCache$1(SmallTableCache.scala:125)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 625, 619, 620, 624, 622, 621, 623 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 174,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:39:55.801GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:39:55.817GMT",
  "completionTime" : "2022-12-20T20:39:55.864GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7788410,
  "executorRunTime" : 23,
  "executorCpuTime" : 18475989,
  "resultSize" : 7123,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 1,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 2,
  "shuffleRemoteBytesRead" : 857,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 614, 613 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 173,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 612, 609, 606, 604, 608, 611, 607, 605, 603, 610 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 172,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 602, 596, 598, 601, 599, 600, 597 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 171,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:39:55.702GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:39:55.726GMT",
  "completionTime" : "2022-12-20T20:39:55.790GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9194559,
  "executorRunTime" : 35,
  "executorCpuTime" : 31349587,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 3,
  "shuffleLocalBlocksFetched" : 2,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 7321,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 930,
  "shuffleReadBytes" : 8251,
  "shuffleReadRecords" : 16,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 523742,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 612, 609, 606, 604, 608, 611, 607, 605, 603, 610 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 170,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 602, 596, 598, 601, 599, 600, 597 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 169,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 5,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 5,
  "submissionTime" : "2022-12-20T20:39:55.502GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:39:55.509GMT",
  "completionTime" : "2022-12-20T20:39:55.606GMT",
  "executorDeserializeTime" : 19,
  "executorDeserializeCpuTime" : 20806968,
  "executorRunTime" : 84,
  "executorCpuTime" : 17611136,
  "resultSize" : 15020,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 82739,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 8251,
  "shuffleWriteTime" : 2304410,
  "shuffleWriteRecords" : 16,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 602, 596, 598, 601, 599, 600, 597 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 168,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:39:55.139GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:39:55.144GMT",
  "completionTime" : "2022-12-20T20:39:55.233GMT",
  "executorDeserializeTime" : 3,
  "executorDeserializeCpuTime" : 3732236,
  "executorRunTime" : 69,
  "executorCpuTime" : 54020950,
  "resultSize" : 3889,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70637,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 595, 593, 594 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 167,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:39:54.521GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:39:54.531GMT",
  "completionTime" : "2022-12-20T20:39:54.789GMT",
  "executorDeserializeTime" : 10,
  "executorDeserializeCpuTime" : 10364881,
  "executorRunTime" : 231,
  "executorCpuTime" : 119327007,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12149,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 592 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 166,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 590, 589, 585, 583, 582, 584, 586, 587 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 165,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:39:54.462GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:39:54.464GMT",
  "completionTime" : "2022-12-20T20:39:54.504GMT",
  "executorDeserializeTime" : 19,
  "executorDeserializeCpuTime" : 22441251,
  "executorRunTime" : 66,
  "executorCpuTime" : 45675615,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4244,
  "shuffleWriteTime" : 260214,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 590, 589, 585, 583, 582, 584, 586, 587 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 164,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:39:00.958GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:39:00.975GMT",
  "completionTime" : "2022-12-20T20:39:01.035GMT",
  "executorDeserializeTime" : 12,
  "executorDeserializeCpuTime" : 11646889,
  "executorRunTime" : 28,
  "executorCpuTime" : 19294102,
  "resultSize" : 7122,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 1,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 6,
  "shuffleRemoteBytesRead" : 857,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 577, 576 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 163,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 575, 573, 568, 567, 566, 574, 571, 569, 572, 570 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 162,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 565, 560, 559, 562, 563, 564, 561 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 161,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:39:00.742GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:39:00.783GMT",
  "completionTime" : "2022-12-20T20:39:00.944GMT",
  "executorDeserializeTime" : 21,
  "executorDeserializeCpuTime" : 19999077,
  "executorRunTime" : 120,
  "executorCpuTime" : 101375276,
  "resultSize" : 4640,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 2,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 6063,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 466,
  "shuffleReadBytes" : 6529,
  "shuffleReadRecords" : 14,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 498940,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 575, 573, 568, 567, 566, 574, 571, 569, 572, 570 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 160,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 565, 560, 559, 562, 563, 564, 561 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 159,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 3,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 3,
  "submissionTime" : "2022-12-20T20:39:00.329GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:39:00.345GMT",
  "completionTime" : "2022-12-20T20:39:00.533GMT",
  "executorDeserializeTime" : 47,
  "executorDeserializeCpuTime" : 36276518,
  "executorRunTime" : 159,
  "executorCpuTime" : 78049853,
  "resultSize" : 9164,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 82739,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 6529,
  "shuffleWriteTime" : 1342856,
  "shuffleWriteRecords" : 14,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 565, 560, 559, 562, 563, 564, 561 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 158,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:38:55.789GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:38:55.796GMT",
  "completionTime" : "2022-12-20T20:38:58.508GMT",
  "executorDeserializeTime" : 134,
  "executorDeserializeCpuTime" : 132770535,
  "executorRunTime" : 2558,
  "executorCpuTime" : 99158857,
  "resultSize" : 3927,
  "jvmGcTime" : 42,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 70637,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at SnapshotEdge.scala:195",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$3(SnapshotEdge.scala:195)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$2(SnapshotEdge.scala:160)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.$anonfun$x$8$1(SnapshotEdge.scala:160)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8$lzycompute(SnapshotEdge.scala:159)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.x$8(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata$lzycompute(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge._metadata(SnapshotEdge.scala:158)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.metadata(SnapshotEdge.scala:239)\ncom.databricks.sql.transaction.tahoe.stats.DataSkippingReaderBase.$init$(DataSkippingReader.scala:184)\ncom.databricks.sql.transaction.tahoe.Snapshot.<init>(Snapshot.scala:78)\ncom.databricks.sql.transaction.tahoe.SnapshotEdge.<init>(SnapshotEdge.scala:78)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 558, 556, 557 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 157,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:38:54.687GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:38:54.696GMT",
  "completionTime" : "2022-12-20T20:38:54.967GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7693585,
  "executorRunTime" : 245,
  "executorCpuTime" : 124429616,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12124,
  "outputRecords" : 8,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 555 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 156,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 553, 549, 548, 546, 550, 547, 552, 545 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 155,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:38:54.555GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:38:54.557GMT",
  "completionTime" : "2022-12-20T20:38:54.672GMT",
  "executorDeserializeTime" : 28,
  "executorDeserializeCpuTime" : 26158532,
  "executorRunTime" : 92,
  "executorCpuTime" : 50331543,
  "resultSize" : 26064,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 268697600,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4826,
  "shuffleWriteTime" : 272514,
  "shuffleWriteRecords" : 8,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 553, 549, 548, 546, 550, 547, 552, 545 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 154,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:37:56.373GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:37:56.390GMT",
  "completionTime" : "2022-12-20T20:37:56.714GMT",
  "executorDeserializeTime" : 28,
  "executorDeserializeCpuTime" : 26468224,
  "executorRunTime" : 275,
  "executorCpuTime" : 152105599,
  "resultSize" : 3320,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 9330,
  "shuffleReadBytes" : 9330,
  "shuffleReadRecords" : 12,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at CheckpointsEdge.scala:313",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.rdd.RDD.collect(RDD.scala:1025)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$2(CheckpointsEdge.scala:313)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.withDmqTag(CheckpointsEdge.scala:177)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$1(CheckpointsEdge.scala:193)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.writeCheckpoint(CheckpointsEdge.scala:193)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles(CheckpointsEdge.scala:173)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles$(CheckpointsEdge.scala:171)\ncom.databricks.sql.transaction.tahoe.DeltaLog.writeCheckpointFiles(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog(Checkpoints.scala:357)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog$(Checkpoints.scala:351)\ncom.databricks.sql.transaction.tahoe.DeltaLog.checkpointAndCleanUpDeltaLog(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.$anonfun$checkpoint$2(Checkpoints.scala:325)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 544, 543, 542 ],
  "accumulatorUpdates" : [ {
    "id" : 5310,
    "name" : "checkpointSizeRows",
    "value" : "12"
  }, {
    "id" : 5313,
    "name" : "checkpointSizeInBytes",
    "value" : "50686"
  }, {
    "id" : 5311,
    "name" : "numOfFiles",
    "value" : "10"
  } ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 153,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at CheckpointsEdge.scala:309",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$2(CheckpointsEdge.scala:309)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.withDmqTag(CheckpointsEdge.scala:177)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$1(CheckpointsEdge.scala:193)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.writeCheckpoint(CheckpointsEdge.scala:193)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles(CheckpointsEdge.scala:173)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles$(CheckpointsEdge.scala:171)\ncom.databricks.sql.transaction.tahoe.DeltaLog.writeCheckpointFiles(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog(Checkpoints.scala:357)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog$(Checkpoints.scala:351)\ncom.databricks.sql.transaction.tahoe.DeltaLog.checkpointAndCleanUpDeltaLog(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.$anonfun$checkpoint$2(Checkpoints.scala:325)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)",
  "schedulingPool" : "default",
  "rddIds" : [ 541, 524, 526, 529, 528, 539, 525, 527, 523, 540 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 152,
  "attemptId" : 0,
  "numTasks" : 16,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 522, 521, 520 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 151,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:37:56.188GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:37:56.210GMT",
  "completionTime" : "2022-12-20T20:37:56.349GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9942924,
  "executorRunTime" : 110,
  "executorCpuTime" : 97227711,
  "resultSize" : 2159,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 5061,
  "inputRecords" : 12,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 9330,
  "shuffleWriteTime" : 480313,
  "shuffleWriteRecords" : 12,
  "name" : "execute at CheckpointsEdge.scala:309",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$2(CheckpointsEdge.scala:309)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.withDmqTag(CheckpointsEdge.scala:177)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.$anonfun$writeCheckpoint$1(CheckpointsEdge.scala:193)\ncom.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:1614)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge$.writeCheckpoint(CheckpointsEdge.scala:193)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles(CheckpointsEdge.scala:173)\ncom.databricks.sql.transaction.tahoe.CheckpointsEdge.writeCheckpointFiles$(CheckpointsEdge.scala:171)\ncom.databricks.sql.transaction.tahoe.DeltaLog.writeCheckpointFiles(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog(Checkpoints.scala:357)\ncom.databricks.sql.transaction.tahoe.Checkpoints.checkpointAndCleanUpDeltaLog$(Checkpoints.scala:351)\ncom.databricks.sql.transaction.tahoe.DeltaLog.checkpointAndCleanUpDeltaLog(DeltaLog.scala:75)\ncom.databricks.sql.transaction.tahoe.Checkpoints.$anonfun$checkpoint$2(Checkpoints.scala:325)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 541, 524, 526, 529, 528, 539, 525, 527, 523, 540 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 150,
  "attemptId" : 0,
  "numTasks" : 16,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 522, 521, 520 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 149,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:37:55.710GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:37:55.722GMT",
  "completionTime" : "2022-12-20T20:37:55.767GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7578382,
  "executorRunTime" : 20,
  "executorCpuTime" : 19245693,
  "resultSize" : 5047,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 534, 533 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 148,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 532, 524, 526, 531, 529, 528, 525, 527, 523, 530 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 147,
  "attemptId" : 0,
  "numTasks" : 16,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 522, 521, 520 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 146,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:37:55.622GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:37:55.645GMT",
  "completionTime" : "2022-12-20T20:37:55.699GMT",
  "executorDeserializeTime" : 6,
  "executorDeserializeCpuTime" : 6477169,
  "executorRunTime" : 31,
  "executorCpuTime" : 22028347,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 8,
  "shuffleLocalBlocksFetched" : 8,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 8485,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 9989,
  "shuffleReadBytes" : 18474,
  "shuffleReadRecords" : 23,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 348810,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 532, 524, 526, 531, 529, 528, 525, 527, 523, 530 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 145,
  "attemptId" : 0,
  "numTasks" : 16,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 522, 521, 520 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 144,
  "attemptId" : 0,
  "numTasks" : 16,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 16,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 16,
  "submissionTime" : "2022-12-20T20:37:55.482GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:37:55.486GMT",
  "completionTime" : "2022-12-20T20:37:55.522GMT",
  "executorDeserializeTime" : 57,
  "executorDeserializeCpuTime" : 25117813,
  "executorRunTime" : 67,
  "executorCpuTime" : 33609558,
  "resultSize" : 17776,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 18474,
  "shuffleWriteTime" : 6113045,
  "shuffleWriteRecords" : 23,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 522, 521, 520 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 143,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:37:54.500GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:37:54.509GMT",
  "completionTime" : "2022-12-20T20:37:54.904GMT",
  "executorDeserializeTime" : 14,
  "executorDeserializeCpuTime" : 13708117,
  "executorRunTime" : 359,
  "executorCpuTime" : 240724439,
  "resultSize" : 5482,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12146,
  "outputRecords" : 6,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 519 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 142,
  "attemptId" : 0,
  "numTasks" : 6,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 517, 509, 512, 516, 514, 513, 511, 510 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 141,
  "attemptId" : 0,
  "numTasks" : 6,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 6,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 6,
  "submissionTime" : "2022-12-20T20:37:54.447GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:37:54.450GMT",
  "completionTime" : "2022-12-20T20:37:54.483GMT",
  "executorDeserializeTime" : 20,
  "executorDeserializeCpuTime" : 21615437,
  "executorRunTime" : 42,
  "executorCpuTime" : 39468384,
  "resultSize" : 19548,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 201523200,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 3675,
  "shuffleWriteTime" : 214813,
  "shuffleWriteRecords" : 6,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 517, 509, 512, 516, 514, 513, 511, 510 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 140,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:36:56.338GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:36:56.353GMT",
  "completionTime" : "2022-12-20T20:36:56.615GMT",
  "executorDeserializeTime" : 36,
  "executorDeserializeCpuTime" : 35370339,
  "executorRunTime" : 203,
  "executorCpuTime" : 175628805,
  "resultSize" : 5048,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 504, 503 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 139,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 502, 500, 499, 493, 501, 495, 494, 496, 498, 497 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 138,
  "attemptId" : 0,
  "numTasks" : 16,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 492, 491, 490 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 137,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:36:55.534GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:36:55.556GMT",
  "completionTime" : "2022-12-20T20:36:56.322GMT",
  "executorDeserializeTime" : 211,
  "executorDeserializeCpuTime" : 209370251,
  "executorRunTime" : 533,
  "executorCpuTime" : 479842064,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 8,
  "shuffleLocalBlocksFetched" : 8,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 8750,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 8117,
  "shuffleReadBytes" : 16867,
  "shuffleReadRecords" : 21,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 510642,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 502, 500, 499, 493, 501, 495, 494, 496, 498, 497 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 136,
  "attemptId" : 0,
  "numTasks" : 16,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 492, 491, 490 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 135,
  "attemptId" : 0,
  "numTasks" : 16,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 16,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 16,
  "submissionTime" : "2022-12-20T20:36:55.386GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:36:55.392GMT",
  "completionTime" : "2022-12-20T20:36:55.435GMT",
  "executorDeserializeTime" : 32,
  "executorDeserializeCpuTime" : 31959896,
  "executorRunTime" : 108,
  "executorCpuTime" : 43448119,
  "resultSize" : 17738,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 16867,
  "shuffleWriteTime" : 9934069,
  "shuffleWriteRecords" : 21,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 492, 491, 490 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 134,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:36:54.521GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:36:54.531GMT",
  "completionTime" : "2022-12-20T20:36:54.853GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7326707,
  "executorRunTime" : 295,
  "executorCpuTime" : 130896079,
  "resultSize" : 5511,
  "jvmGcTime" : 37,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12212,
  "outputRecords" : 7,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 489 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 133,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 487, 486, 481, 482, 479, 480, 483, 484 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 132,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:36:54.450GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:36:54.452GMT",
  "completionTime" : "2022-12-20T20:36:54.505GMT",
  "executorDeserializeTime" : 30,
  "executorDeserializeCpuTime" : 31552460,
  "executorRunTime" : 95,
  "executorCpuTime" : 82241508,
  "resultSize" : 22806,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 235110400,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4278,
  "shuffleWriteTime" : 260011,
  "shuffleWriteRecords" : 7,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 487, 486, 481, 482, 479, 480, 483, 484 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 131,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:36:06.979GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:36:06.997GMT",
  "completionTime" : "2022-12-20T20:36:07.043GMT",
  "executorDeserializeTime" : 6,
  "executorDeserializeCpuTime" : 6982339,
  "executorRunTime" : 20,
  "executorCpuTime" : 18750496,
  "resultSize" : 5049,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 856,
  "shuffleReadBytes" : 856,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 474, 473 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 130,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 472, 468, 469, 470, 463, 471, 467, 464, 465, 466 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 129,
  "attemptId" : 0,
  "numTasks" : 16,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 462, 460, 461 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 128,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:36:06.852GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:36:06.881GMT",
  "completionTime" : "2022-12-20T20:36:06.967GMT",
  "executorDeserializeTime" : 6,
  "executorDeserializeCpuTime" : 6769691,
  "executorRunTime" : 62,
  "executorCpuTime" : 39001613,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 8,
  "shuffleLocalBlocksFetched" : 8,
  "shuffleFetchWaitTime" : 10,
  "shuffleRemoteBytesRead" : 7793,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 7473,
  "shuffleReadBytes" : 15266,
  "shuffleReadRecords" : 19,
  "shuffleWriteBytes" : 856,
  "shuffleWriteTime" : 368011,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 472, 468, 469, 470, 463, 471, 467, 464, 465, 466 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 127,
  "attemptId" : 0,
  "numTasks" : 16,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 462, 460, 461 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 126,
  "attemptId" : 0,
  "numTasks" : 16,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 16,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 16,
  "submissionTime" : "2022-12-20T20:36:06.561GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:36:06.567GMT",
  "completionTime" : "2022-12-20T20:36:06.644GMT",
  "executorDeserializeTime" : 72,
  "executorDeserializeCpuTime" : 45588134,
  "executorRunTime" : 312,
  "executorCpuTime" : 86142595,
  "resultSize" : 17738,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 15266,
  "shuffleWriteTime" : 80158593,
  "shuffleWriteRecords" : 19,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 462, 460, 461 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 125,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:35:59.502GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:35:59.511GMT",
  "completionTime" : "2022-12-20T20:36:05.932GMT",
  "executorDeserializeTime" : 354,
  "executorDeserializeCpuTime" : 314111931,
  "executorRunTime" : 6024,
  "executorCpuTime" : 5265932234,
  "resultSize" : 5824,
  "jvmGcTime" : 46,
  "resultSerializationTime" : 10,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12212,
  "outputRecords" : 6,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 3,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 1912,
  "shuffleReadBytes" : 1912,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 459 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 212635968,
    "JVMOffHeapMemory" : 150054232,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 863157,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 863157,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 43526,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 15,
    "MinorGCTime" : 123,
    "MajorGCCount" : 4,
    "MajorGCTime" : 237,
    "TotalGCTime" : 360
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 124,
  "attemptId" : 0,
  "numTasks" : 6,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 457, 453, 451, 449, 452, 454, 450, 456 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 123,
  "attemptId" : 0,
  "numTasks" : 6,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 6,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 6,
  "submissionTime" : "2022-12-20T20:35:54.847GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:35:54.850GMT",
  "completionTime" : "2022-12-20T20:35:59.483GMT",
  "executorDeserializeTime" : 3093,
  "executorDeserializeCpuTime" : 1498497448,
  "executorRunTime" : 9883,
  "executorCpuTime" : 3481009339,
  "resultSize" : 19738,
  "jvmGcTime" : 306,
  "resultSerializationTime" : 2,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 201523200,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 3690,
  "shuffleWriteTime" : 287618,
  "shuffleWriteRecords" : 6,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 457, 453, 451, 449, 452, 454, 450, 456 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 4333997288,
    "JVMOffHeapMemory" : 229859400,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 2206055,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 2206055,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 18600988,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 211,
    "MinorGCTime" : 3435,
    "MajorGCCount" : 14,
    "MajorGCTime" : 2236,
    "TotalGCTime" : 5671
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 122,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:34:55.486GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:55.499GMT",
  "completionTime" : "2022-12-20T20:34:55.543GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7931538,
  "executorRunTime" : 19,
  "executorCpuTime" : 18526184,
  "resultSize" : 5044,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 859,
  "shuffleReadBytes" : 859,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 444, 443 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 121,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 442, 439, 438, 434, 440, 437, 441, 436, 433, 435 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 120,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 432, 430, 431 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 119,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:34:55.401GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:55.425GMT",
  "completionTime" : "2022-12-20T20:34:55.475GMT",
  "executorDeserializeTime" : 10,
  "executorDeserializeCpuTime" : 10889802,
  "executorRunTime" : 24,
  "executorCpuTime" : 21305345,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 8,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 12266,
  "shuffleReadBytes" : 12266,
  "shuffleReadRecords" : 17,
  "shuffleWriteBytes" : 859,
  "shuffleWriteTime" : 369110,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 442, 439, 438, 434, 440, 437, 441, 436, 433, 435 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 118,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 432, 430, 431 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 117,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:34:55.275GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:55.279GMT",
  "completionTime" : "2022-12-20T20:34:55.299GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 9556474,
  "executorRunTime" : 16,
  "executorCpuTime" : 13317414,
  "resultSize" : 8812,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 12266,
  "shuffleWriteTime" : 2860973,
  "shuffleWriteRecords" : 17,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 432, 430, 431 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 116,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:34:54.495GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:54.505GMT",
  "completionTime" : "2022-12-20T20:34:54.767GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7542301,
  "executorRunTime" : 238,
  "executorCpuTime" : 133133574,
  "resultSize" : 5557,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12907,
  "outputRecords" : 21,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 429 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 115,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 427, 419, 424, 426, 422, 423, 420, 421 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 114,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:34:54.446GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:54.450GMT",
  "completionTime" : "2022-12-20T20:34:54.479GMT",
  "executorDeserializeTime" : 23,
  "executorDeserializeCpuTime" : 20153923,
  "executorRunTime" : 55,
  "executorCpuTime" : 40567596,
  "resultSize" : 26064,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 268697600,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 6125,
  "shuffleWriteTime" : 286604,
  "shuffleWriteRecords" : 21,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 427, 419, 424, 426, 422, 423, 420, 421 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 113,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:34:14.764GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:14.780GMT",
  "completionTime" : "2022-12-20T20:34:14.822GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7325450,
  "executorRunTime" : 19,
  "executorCpuTime" : 18099517,
  "resultSize" : 5043,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 859,
  "shuffleReadBytes" : 859,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 414, 413 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 112,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 412, 404, 409, 405, 407, 406, 408, 403, 411, 410 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 111,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 402, 401, 400 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 110,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:34:14.667GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:14.702GMT",
  "completionTime" : "2022-12-20T20:34:14.753GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9106859,
  "executorRunTime" : 24,
  "executorCpuTime" : 20577932,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 8,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 11436,
  "shuffleReadBytes" : 11436,
  "shuffleReadRecords" : 15,
  "shuffleWriteBytes" : 859,
  "shuffleWriteTime" : 369509,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 412, 404, 409, 405, 407, 406, 408, 403, 411, 410 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 109,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 402, 401, 400 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 108,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:34:14.533GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:14.538GMT",
  "completionTime" : "2022-12-20T20:34:14.561GMT",
  "executorDeserializeTime" : 12,
  "executorDeserializeCpuTime" : 9795204,
  "executorRunTime" : 12,
  "executorCpuTime" : 14557452,
  "resultSize" : 8888,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 11436,
  "shuffleWriteTime" : 2933778,
  "shuffleWriteRecords" : 15,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 402, 401, 400 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 107,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:34:13.838GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:13.849GMT",
  "completionTime" : "2022-12-20T20:34:14.070GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7665704,
  "executorRunTime" : 195,
  "executorCpuTime" : 107283370,
  "resultSize" : 5535,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12179,
  "outputRecords" : 6,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 399 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 106,
  "attemptId" : 0,
  "numTasks" : 6,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 397, 396, 394, 392, 393, 389, 390, 391 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 105,
  "attemptId" : 0,
  "numTasks" : 6,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 6,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 6,
  "submissionTime" : "2022-12-20T20:34:13.772GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:13.776GMT",
  "completionTime" : "2022-12-20T20:34:13.806GMT",
  "executorDeserializeTime" : 16,
  "executorDeserializeCpuTime" : 15545673,
  "executorRunTime" : 40,
  "executorCpuTime" : 31434326,
  "resultSize" : 19548,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 201523200,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 3912,
  "shuffleWriteTime" : 181906,
  "shuffleWriteRecords" : 6,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 397, 396, 394, 392, 393, 389, 390, 391 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 104,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:34:11.301GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:11.317GMT",
  "completionTime" : "2022-12-20T20:34:11.364GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8054808,
  "executorRunTime" : 22,
  "executorCpuTime" : 20560750,
  "resultSize" : 4805,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 632,
  "shuffleReadBytes" : 632,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "Execution of flow top_spark_referrers",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 384, 383 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 103,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 382, 378, 377, 375, 380, 381, 374, 376, 379, 373 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 102,
  "attemptId" : 0,
  "numTasks" : 6,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 372, 371, 370 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 101,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:34:11.210GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:11.240GMT",
  "completionTime" : "2022-12-20T20:34:11.288GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7182387,
  "executorRunTime" : 22,
  "executorCpuTime" : 19823153,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 6,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 2013,
  "shuffleReadBytes" : 2013,
  "shuffleReadRecords" : 6,
  "shuffleWriteBytes" : 632,
  "shuffleWriteTime" : 395811,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "Execution of flow top_spark_referrers",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 382, 378, 377, 375, 380, 381, 374, 376, 379, 373 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 100,
  "attemptId" : 0,
  "numTasks" : 6,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 372, 371, 370 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 99,
  "attemptId" : 0,
  "numTasks" : 6,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 6,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 6,
  "submissionTime" : "2022-12-20T20:34:11.086GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:11.091GMT",
  "completionTime" : "2022-12-20T20:34:11.111GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 6940700,
  "executorRunTime" : 13,
  "executorCpuTime" : 10206722,
  "resultSize" : 6666,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 2013,
  "shuffleWriteTime" : 2254161,
  "shuffleWriteRecords" : 6,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "Execution of flow top_spark_referrers",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 372, 371, 370 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 98,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:34:10.250GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:10.263GMT",
  "completionTime" : "2022-12-20T20:34:10.445GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8693951,
  "executorRunTime" : 153,
  "executorCpuTime" : 66190829,
  "resultSize" : 17954,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 1037,
  "outputRecords" : 10,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 307,
  "shuffleReadBytes" : 307,
  "shuffleReadRecords" : 10,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "Execution of flow top_spark_referrers",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 369, 367, 368 ],
  "accumulatorUpdates" : [ {
    "id" : 3568,
    "name" : "Collected metrics",
    "value" : "[0,a,0,0]"
  } ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 97,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 3,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 3,
  "submissionTime" : "2022-12-20T20:34:05.879GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:05.881GMT",
  "completionTime" : "2022-12-20T20:34:10.249GMT",
  "executorDeserializeTime" : 60,
  "executorDeserializeCpuTime" : 27741268,
  "executorRunTime" : 8176,
  "executorCpuTime" : 4277287904,
  "resultSize" : 11620,
  "jvmGcTime" : 91,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 207668363,
  "inputRecords" : 13639797,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 307,
  "shuffleWriteTime" : 408511,
  "shuffleWriteRecords" : 10,
  "name" : "execute at DeltaInvariantCheckerExec.scala:82",
  "description" : "Execution of flow top_spark_referrers",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.constraints.DeltaInvariantCheckerExec.doExecute(DeltaInvariantCheckerExec.scala:82)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:206)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 366, 364, 363, 355, 365 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 3026562080,
    "JVMOffHeapMemory" : 227320184,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 5024890,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 5024890,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 18617535,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 210,
    "MinorGCTime" : 3406,
    "MajorGCCount" : 14,
    "MajorGCTime" : 2236,
    "TotalGCTime" : 5642
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 96,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:34:04.944GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:04.962GMT",
  "completionTime" : "2022-12-20T20:34:05.007GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7509127,
  "executorRunTime" : 21,
  "executorCpuTime" : 20009250,
  "resultSize" : 4816,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 665,
  "shuffleReadBytes" : 665,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "Execution of flow clickstream_prepared",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 350, 349 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 95,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 348, 346, 343, 339, 345, 342, 347, 344, 340, 341 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 94,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 338, 337, 336 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 93,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:34:04.855GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:04.885GMT",
  "completionTime" : "2022-12-20T20:34:04.933GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7081988,
  "executorRunTime" : 24,
  "executorCpuTime" : 20166783,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 7,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 2525,
  "shuffleReadBytes" : 2525,
  "shuffleReadRecords" : 7,
  "shuffleWriteBytes" : 665,
  "shuffleWriteTime" : 379810,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "Execution of flow clickstream_prepared",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 348, 346, 343, 339, 345, 342, 347, 344, 340, 341 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 92,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 338, 337, 336 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 91,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:34:04.671GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:34:04.676GMT",
  "completionTime" : "2022-12-20T20:34:04.697GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9944668,
  "executorRunTime" : 20,
  "executorCpuTime" : 12448214,
  "resultSize" : 7777,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 2525,
  "shuffleWriteTime" : 4041309,
  "shuffleWriteRecords" : 7,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "Execution of flow clickstream_prepared",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 338, 337, 336 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 90,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:33:56.309GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:56.330GMT",
  "completionTime" : "2022-12-20T20:33:56.377GMT",
  "executorDeserializeTime" : 6,
  "executorDeserializeCpuTime" : 6965321,
  "executorRunTime" : 21,
  "executorCpuTime" : 19971541,
  "resultSize" : 5045,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 857,
  "shuffleReadBytes" : 857,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 331, 330 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 89,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 329, 323, 322, 321, 320, 327, 328, 324, 326, 325 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 88,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 319, 317, 318 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 87,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:33:56.202GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:56.245GMT",
  "completionTime" : "2022-12-20T20:33:56.293GMT",
  "executorDeserializeTime" : 6,
  "executorDeserializeCpuTime" : 6697674,
  "executorRunTime" : 24,
  "executorCpuTime" : 21423031,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 8,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 9788,
  "shuffleReadBytes" : 9788,
  "shuffleReadRecords" : 13,
  "shuffleWriteBytes" : 857,
  "shuffleWriteTime" : 428713,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 329, 323, 322, 321, 320, 327, 328, 324, 326, 325 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 86,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 319, 317, 318 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 85,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:33:55.913GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:55.919GMT",
  "completionTime" : "2022-12-20T20:33:55.943GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 8395433,
  "executorRunTime" : 17,
  "executorCpuTime" : 13083770,
  "resultSize" : 8812,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 9788,
  "shuffleWriteTime" : 2998079,
  "shuffleWriteRecords" : 13,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 319, 317, 318 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 84,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:33:54.982GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:54.992GMT",
  "completionTime" : "2022-12-20T20:33:55.237GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9491507,
  "executorRunTime" : 218,
  "executorCpuTime" : 123220977,
  "resultSize" : 5568,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12809,
  "outputRecords" : 17,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 316 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 83,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 314, 306, 313, 311, 308, 307, 309, 310 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 82,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:33:54.898GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:54.900GMT",
  "completionTime" : "2022-12-20T20:33:54.945GMT",
  "executorDeserializeTime" : 20,
  "executorDeserializeCpuTime" : 19855813,
  "executorRunTime" : 78,
  "executorCpuTime" : 41090446,
  "resultSize" : 26064,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 268697600,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 5724,
  "shuffleWriteTime" : 241504,
  "shuffleWriteRecords" : 17,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 314, 306, 313, 311, 308, 307, 309, 310 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 81,
  "attemptId" : 0,
  "numTasks" : 2,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 2,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 2,
  "submissionTime" : "2022-12-20T20:33:45.154GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:45.221GMT",
  "completionTime" : "2022-12-20T20:34:03.854GMT",
  "executorDeserializeTime" : 16,
  "executorDeserializeCpuTime" : 15425356,
  "executorRunTime" : 26383,
  "executorCpuTime" : 24660558874,
  "resultSize" : 8433,
  "jvmGcTime" : 232,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 343092202,
  "outputRecords" : 22509897,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 5,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 632972908,
  "shuffleReadBytes" : 632972908,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "Execution of flow clickstream_prepared",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 305 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 3550177584,
    "JVMOffHeapMemory" : 226636864,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 3406441,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 3406441,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 18617535,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 207,
    "MinorGCTime" : 3365,
    "MajorGCCount" : 14,
    "MajorGCTime" : 2236,
    "TotalGCTime" : 5601
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 80,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 273, 270, 272, 271, 266 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 79,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:33:25.524GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:25.540GMT",
  "completionTime" : "2022-12-20T20:33:25.593GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7471352,
  "executorRunTime" : 29,
  "executorCpuTime" : 28587083,
  "resultSize" : 5042,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 856,
  "shuffleReadBytes" : 856,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 300, 299 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 78,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 298, 293, 291, 296, 295, 290, 294, 297, 292, 289 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 77,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 288, 286, 287 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 76,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:33:25.431GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:25.459GMT",
  "completionTime" : "2022-12-20T20:33:25.512GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8028054,
  "executorRunTime" : 29,
  "executorCpuTime" : 25652930,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 8,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 8146,
  "shuffleReadBytes" : 8146,
  "shuffleReadRecords" : 11,
  "shuffleWriteBytes" : 856,
  "shuffleWriteTime" : 440812,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 298, 293, 291, 296, 295, 290, 294, 297, 292, 289 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 75,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 288, 286, 287 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 74,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:33:25.290GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:25.295GMT",
  "completionTime" : "2022-12-20T20:33:25.329GMT",
  "executorDeserializeTime" : 4,
  "executorDeserializeCpuTime" : 8635709,
  "executorRunTime" : 11,
  "executorCpuTime" : 13643221,
  "resultSize" : 8736,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 8146,
  "shuffleWriteTime" : 2892277,
  "shuffleWriteRecords" : 11,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 288, 286, 287 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 73,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:33:24.499GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:24.509GMT",
  "completionTime" : "2022-12-20T20:33:24.822GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8923316,
  "executorRunTime" : 286,
  "executorCpuTime" : 137666260,
  "resultSize" : 5580,
  "jvmGcTime" : 47,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12283,
  "outputRecords" : 4,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 285 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 72,
  "attemptId" : 0,
  "numTasks" : 4,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 283, 279, 278, 282, 280, 276, 277, 275 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 71,
  "attemptId" : 0,
  "numTasks" : 4,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 4,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 4,
  "submissionTime" : "2022-12-20T20:33:24.424GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:24.427GMT",
  "completionTime" : "2022-12-20T20:33:24.467GMT",
  "executorDeserializeTime" : 12,
  "executorDeserializeCpuTime" : 10035821,
  "executorRunTime" : 34,
  "executorCpuTime" : 21743866,
  "resultSize" : 13032,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 134348800,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 2626,
  "shuffleWriteTime" : 135004,
  "shuffleWriteRecords" : 4,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 283, 279, 278, 282, 280, 276, 277, 275 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 70,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 5,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 5,
  "submissionTime" : "2022-12-20T20:33:23.785GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:23.831GMT",
  "completionTime" : "2022-12-20T20:33:45.135GMT",
  "executorDeserializeTime" : 224,
  "executorDeserializeCpuTime" : 92423023,
  "executorRunTime" : 81245,
  "executorCpuTime" : 62392809474,
  "resultSize" : 97335,
  "jvmGcTime" : 8815,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 2466250752,
  "inputBytes" : 495972052,
  "inputRecords" : 22509897,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 632972908,
  "shuffleWriteTime" : 612157075,
  "shuffleWriteRecords" : 22509897,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "Execution of flow clickstream_prepared",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 273, 270, 272, 271, 266 ],
  "accumulatorUpdates" : [ {
    "id" : 2637,
    "name" : "Collected metrics",
    "value" : "[0,1577949,5,0,0,5]"
  } ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 3734930280,
    "JVMOffHeapMemory" : 225911296,
    "OnHeapExecutionMemory" : 1543503872,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 9301306,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 1552805178,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 18617535,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 191,
    "MinorGCTime" : 2897,
    "MajorGCCount" : 13,
    "MajorGCTime" : 1929,
    "TotalGCTime" : 4826
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 69,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:33:22.385GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:22.416GMT",
  "completionTime" : "2022-12-20T20:33:22.465GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8936802,
  "executorRunTime" : 22,
  "executorCpuTime" : 20784937,
  "resultSize" : 4793,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 661,
  "shuffleReadBytes" : 661,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "Execution of flow clickstream_raw",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 261, 260 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 68,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 259, 250, 252, 257, 258, 253, 254, 255, 251, 256 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 67,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 249, 247, 248 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 66,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:33:22.299GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:22.318GMT",
  "completionTime" : "2022-12-20T20:33:22.373GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7319092,
  "executorRunTime" : 27,
  "executorCpuTime" : 23009611,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 8,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 3195,
  "shuffleReadBytes" : 3195,
  "shuffleReadRecords" : 8,
  "shuffleWriteBytes" : 661,
  "shuffleWriteTime" : 378511,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "Execution of flow clickstream_raw",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 259, 250, 252, 257, 258, 253, 254, 255, 251, 256 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 65,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 249, 247, 248 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 64,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:33:22.095GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:33:22.100GMT",
  "completionTime" : "2022-12-20T20:33:22.123GMT",
  "executorDeserializeTime" : 11,
  "executorDeserializeCpuTime" : 9358455,
  "executorRunTime" : 19,
  "executorCpuTime" : 13811310,
  "resultSize" : 8850,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 3195,
  "shuffleWriteTime" : 2756875,
  "shuffleWriteRecords" : 8,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "Execution of flow clickstream_raw",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 249, 247, 248 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 63,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:32:56.426GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:32:56.441GMT",
  "completionTime" : "2022-12-20T20:32:56.487GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7324913,
  "executorRunTime" : 23,
  "executorCpuTime" : 22205966,
  "resultSize" : 5045,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 856,
  "shuffleReadBytes" : 856,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 242, 241 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 62,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 240, 234, 235, 237, 239, 231, 238, 236, 232, 233 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 61,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 230, 228, 229 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 60,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:32:56.333GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:32:56.358GMT",
  "completionTime" : "2022-12-20T20:32:56.414GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7137689,
  "executorRunTime" : 30,
  "executorCpuTime" : 25237005,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 8,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 6464,
  "shuffleReadBytes" : 6464,
  "shuffleReadRecords" : 9,
  "shuffleWriteBytes" : 856,
  "shuffleWriteTime" : 435013,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 240, 234, 235, 237, 239, 231, 238, 236, 232, 233 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 59,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 230, 228, 229 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 58,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:32:56.186GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:32:56.190GMT",
  "completionTime" : "2022-12-20T20:32:56.221GMT",
  "executorDeserializeTime" : 13,
  "executorDeserializeCpuTime" : 8134785,
  "executorRunTime" : 18,
  "executorCpuTime" : 13171609,
  "resultSize" : 8736,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 6464,
  "shuffleWriteTime" : 3305888,
  "shuffleWriteRecords" : 9,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 230, 228, 229 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 57,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 3,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 3,
  "submissionTime" : "2022-12-20T20:32:55.450GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:32:55.461GMT",
  "completionTime" : "2022-12-20T20:33:21.223GMT",
  "executorDeserializeTime" : 29,
  "executorDeserializeCpuTime" : 30123224,
  "executorRunTime" : 54600,
  "executorCpuTime" : 51975841431,
  "resultSize" : 12870,
  "jvmGcTime" : 577,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 496100715,
  "outputRecords" : 22509897,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 21,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 1004958945,
  "shuffleReadBytes" : 1004958945,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "Execution of flow clickstream_raw",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 227 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 2776363248,
    "JVMOffHeapMemory" : 218281240,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 6063650,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 6063650,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 7074109,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 168,
    "MinorGCTime" : 1956,
    "MajorGCCount" : 11,
    "MajorGCTime" : 1356,
    "TotalGCTime" : 3312
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 56,
  "attemptId" : 0,
  "numTasks" : 21,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 214, 213, 212, 209 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 55,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:32:54.975GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:32:54.987GMT",
  "completionTime" : "2022-12-20T20:32:55.349GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9994805,
  "executorRunTime" : 333,
  "executorCpuTime" : 178607294,
  "resultSize" : 5542,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 14722,
  "outputRecords" : 25,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 226 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 54,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 224, 216, 217, 221, 220, 219, 218, 223 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 53,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:32:54.871GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:32:54.874GMT",
  "completionTime" : "2022-12-20T20:32:54.942GMT",
  "executorDeserializeTime" : 22,
  "executorDeserializeCpuTime" : 19327087,
  "executorRunTime" : 88,
  "executorCpuTime" : 52750491,
  "resultSize" : 26064,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 268697600,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 9057,
  "shuffleWriteTime" : 255407,
  "shuffleWriteRecords" : 25,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 224, 216, 217, 221, 220, 219, 218, 223 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 52,
  "attemptId" : 0,
  "numTasks" : 21,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 21,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 21,
  "submissionTime" : "2022-12-20T20:32:39.302GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:32:39.305GMT",
  "completionTime" : "2022-12-20T20:32:55.430GMT",
  "executorDeserializeTime" : 176,
  "executorDeserializeCpuTime" : 81094703,
  "executorRunTime" : 114340,
  "executorCpuTime" : 84517031798,
  "resultSize" : 351078,
  "jvmGcTime" : 14772,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 4194304000,
  "inputBytes" : 2815376880,
  "inputRecords" : 22509897,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 1004958945,
  "shuffleWriteTime" : 1172140818,
  "shuffleWriteRecords" : 22509897,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "Execution of flow clickstream_raw",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 214, 213, 212, 209 ],
  "accumulatorUpdates" : [ {
    "id" : 2011,
    "name" : "Collected metrics",
    "value" : "[0,1577949,0,0]"
  } ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 725221384,
    "JVMOffHeapMemory" : 213820616,
    "OnHeapExecutionMemory" : 603979776,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 4106918,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 608086694,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 2465484,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 138,
    "MinorGCTime" : 1369,
    "MajorGCCount" : 9,
    "MajorGCTime" : 1109,
    "TotalGCTime" : 2478
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 51,
  "attemptId" : 0,
  "numTasks" : 21,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 21,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 21,
  "submissionTime" : "2022-12-20T20:32:27.216GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:32:27.223GMT",
  "completionTime" : "2022-12-20T20:32:38.389GMT",
  "executorDeserializeTime" : 47,
  "executorDeserializeCpuTime" : 53961276,
  "executorRunTime" : 75659,
  "executorCpuTime" : 51889630083,
  "resultSize" : 72030,
  "jvmGcTime" : 592,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 2815392487,
  "inputRecords" : 22509897,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "json at NativeMethodAccessorImpl.java:0",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:496)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\npy4j.Gateway.invoke(Gateway.java:306)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.sendCommand(ClientServerConnection.java:257)\npy4j.CallbackClient.sendCommand(CallbackClient.java:384)\npy4j.CallbackClient.sendCommand(CallbackClient.java:356)\npy4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\ncom.sun.proxy.$Proxy86.call(Unknown Source)\ncom.databricks.pipelines.Pipeline$DatasetBuilderImpl.$anonfun$query$1(Pipeline.scala:269)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$3(Pipeline.scala:653)\ncom.databricks.pipelines.Pipeline.withContext(Pipeline.scala:101)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$2(Pipeline.scala:653)\nscala.util.Try$.apply(Try.scala:213)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 208, 206, 207, 205 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 2608496736,
    "JVMOffHeapMemory" : 210810768,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 3434244,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 3434244,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 2453351,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 119,
    "MinorGCTime" : 803,
    "MajorGCCount" : 5,
    "MajorGCTime" : 383,
    "TotalGCTime" : 1186
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 50,
  "attemptId" : 0,
  "numTasks" : 21,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 21,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 21,
  "submissionTime" : "2022-12-20T20:32:10.580GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:32:10.584GMT",
  "completionTime" : "2022-12-20T20:32:25.275GMT",
  "executorDeserializeTime" : 39,
  "executorDeserializeCpuTime" : 44460299,
  "executorRunTime" : 90638,
  "executorCpuTime" : 51830808916,
  "resultSize" : 72030,
  "jvmGcTime" : 647,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 2815415428,
  "inputRecords" : 22509897,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "json at NativeMethodAccessorImpl.java:0",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:496)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\npy4j.Gateway.invoke(Gateway.java:306)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.sendCommand(ClientServerConnection.java:257)\npy4j.CallbackClient.sendCommand(CallbackClient.java:384)\npy4j.CallbackClient.sendCommand(CallbackClient.java:356)\npy4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\ncom.sun.proxy.$Proxy86.call(Unknown Source)\ncom.databricks.pipelines.Pipeline$DatasetBuilderImpl.$anonfun$query$1(Pipeline.scala:269)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$3(Pipeline.scala:653)\ncom.databricks.pipelines.Pipeline.withContext(Pipeline.scala:101)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$2(Pipeline.scala:653)\nscala.util.Try$.apply(Try.scala:213)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 204, 202, 201, 203 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 393122264,
    "JVMOffHeapMemory" : 208595112,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 2738578,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 2738578,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 2453351,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 100,
    "MinorGCTime" : 692,
    "MajorGCCount" : 5,
    "MajorGCTime" : 383,
    "TotalGCTime" : 1075
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 49,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:31:59.165GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:59.247GMT",
  "completionTime" : "2022-12-20T20:31:59.297GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7409994,
  "executorRunTime" : 23,
  "executorCpuTime" : 22254258,
  "resultSize" : 5044,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 856,
  "shuffleReadBytes" : 856,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 196, 195 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 48,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 194, 193, 192, 191, 185, 189, 188, 190, 187, 186 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 47,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 184, 183, 182 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 46,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:31:59.004GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:59.077GMT",
  "completionTime" : "2022-12-20T20:31:59.152GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 7700607,
  "executorRunTime" : 45,
  "executorCpuTime" : 31286263,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 7,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 4724,
  "shuffleReadBytes" : 4724,
  "shuffleReadRecords" : 7,
  "shuffleWriteBytes" : 856,
  "shuffleWriteTime" : 386110,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 194, 193, 192, 191, 185, 189, 188, 190, 187, 186 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 45,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 184, 183, 182 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 44,
  "attemptId" : 0,
  "numTasks" : 7,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2022-12-20T20:31:55.971GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:58.710GMT",
  "completionTime" : "2022-12-20T20:31:58.787GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 8854969,
  "executorRunTime" : 18,
  "executorCpuTime" : 14012678,
  "resultSize" : 7777,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 4724,
  "shuffleWriteTime" : 2907376,
  "shuffleWriteRecords" : 7,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 184, 183, 182 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 43,
  "attemptId" : 0,
  "numTasks" : 21,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 21,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 21,
  "submissionTime" : "2022-12-20T20:31:55.406GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:55.409GMT",
  "completionTime" : "2022-12-20T20:32:09.157GMT",
  "executorDeserializeTime" : 43,
  "executorDeserializeCpuTime" : 45498404,
  "executorRunTime" : 88724,
  "executorCpuTime" : 51864231435,
  "resultSize" : 72030,
  "jvmGcTime" : 647,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 2815385650,
  "inputRecords" : 22509897,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "json at NativeMethodAccessorImpl.java:0",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:496)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\npy4j.Gateway.invoke(Gateway.java:306)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.sendCommand(ClientServerConnection.java:257)\npy4j.CallbackClient.sendCommand(CallbackClient.java:384)\npy4j.CallbackClient.sendCommand(CallbackClient.java:356)\npy4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\ncom.sun.proxy.$Proxy86.call(Unknown Source)\ncom.databricks.pipelines.Pipeline$DatasetBuilderImpl.$anonfun$query$1(Pipeline.scala:269)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$3(Pipeline.scala:653)\ncom.databricks.pipelines.Pipeline.withContext(Pipeline.scala:101)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$2(Pipeline.scala:653)\nscala.util.Try$.apply(Try.scala:213)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 181, 179, 178, 180 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 2308523848,
    "JVMOffHeapMemory" : 208135152,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 2042921,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 2042921,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 2453351,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 91,
    "MinorGCTime" : 635,
    "MajorGCCount" : 5,
    "MajorGCTime" : 383,
    "TotalGCTime" : 1018
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 42,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:31:54.953GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:54.963GMT",
  "completionTime" : "2022-12-20T20:31:55.307GMT",
  "executorDeserializeTime" : 13,
  "executorDeserializeCpuTime" : 13024283,
  "executorRunTime" : 310,
  "executorCpuTime" : 187962773,
  "resultSize" : 5492,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 12501,
  "outputRecords" : 19,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 177 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 41,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 175, 167, 174, 170, 168, 171, 172, 169 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 40,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:31:54.866GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:54.869GMT",
  "completionTime" : "2022-12-20T20:31:54.917GMT",
  "executorDeserializeTime" : 29,
  "executorDeserializeCpuTime" : 23463936,
  "executorRunTime" : 85,
  "executorCpuTime" : 72802419,
  "resultSize" : 26064,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 268697600,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 5516,
  "shuffleWriteTime" : 282108,
  "shuffleWriteRecords" : 19,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 175, 167, 174, 170, 168, 171, 172, 169 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 39,
  "attemptId" : 0,
  "numTasks" : 21,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 21,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 21,
  "submissionTime" : "2022-12-20T20:31:37.488GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:37.491GMT",
  "completionTime" : "2022-12-20T20:31:53.574GMT",
  "executorDeserializeTime" : 39,
  "executorDeserializeCpuTime" : 47418867,
  "executorRunTime" : 99018,
  "executorCpuTime" : 51574904033,
  "resultSize" : 72030,
  "jvmGcTime" : 619,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 2815362740,
  "inputRecords" : 22509897,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "json at NativeMethodAccessorImpl.java:0",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:496)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\npy4j.Gateway.invoke(Gateway.java:306)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.sendCommand(ClientServerConnection.java:257)\npy4j.CallbackClient.sendCommand(CallbackClient.java:384)\npy4j.CallbackClient.sendCommand(CallbackClient.java:356)\npy4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\ncom.sun.proxy.$Proxy86.call(Unknown Source)\ncom.databricks.pipelines.Pipeline$DatasetBuilderImpl.$anonfun$query$1(Pipeline.scala:269)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$3(Pipeline.scala:653)\ncom.databricks.pipelines.Pipeline.withContext(Pipeline.scala:101)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$2(Pipeline.scala:653)\nscala.util.Try$.apply(Try.scala:213)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 166, 165, 163, 164 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 466352968,
    "JVMOffHeapMemory" : 205874008,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 6745824,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 6745824,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 2452951,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 74,
    "MinorGCTime" : 533,
    "MajorGCCount" : 5,
    "MajorGCTime" : 383,
    "TotalGCTime" : 916
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 38,
  "attemptId" : 0,
  "numTasks" : 21,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 21,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 21,
  "submissionTime" : "2022-12-20T20:31:21.223GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:21.225GMT",
  "completionTime" : "2022-12-20T20:31:35.662GMT",
  "executorDeserializeTime" : 53,
  "executorDeserializeCpuTime" : 52341909,
  "executorRunTime" : 99721,
  "executorCpuTime" : 52554773852,
  "resultSize" : 72030,
  "jvmGcTime" : 580,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 2815409819,
  "inputRecords" : 22509897,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "json at NativeMethodAccessorImpl.java:0",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:496)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\npy4j.Gateway.invoke(Gateway.java:306)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.sendCommand(ClientServerConnection.java:257)\npy4j.CallbackClient.sendCommand(CallbackClient.java:384)\npy4j.CallbackClient.sendCommand(CallbackClient.java:356)\npy4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\ncom.sun.proxy.$Proxy86.call(Unknown Source)\ncom.databricks.pipelines.Pipeline$DatasetBuilderImpl.$anonfun$query$1(Pipeline.scala:269)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$3(Pipeline.scala:653)\ncom.databricks.pipelines.Pipeline.withContext(Pipeline.scala:101)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$2(Pipeline.scala:653)\nscala.util.Try$.apply(Try.scala:213)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 162, 160, 161, 159 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 806746152,
    "JVMOffHeapMemory" : 204674256,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 6050159,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 6050159,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 2451453,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 55,
    "MinorGCTime" : 420,
    "MajorGCCount" : 5,
    "MajorGCTime" : 383,
    "TotalGCTime" : 803
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 37,
  "attemptId" : 0,
  "numTasks" : 21,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 21,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 21,
  "submissionTime" : "2022-12-20T20:31:07.618GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:07.620GMT",
  "completionTime" : "2022-12-20T20:31:19.722GMT",
  "executorDeserializeTime" : 55,
  "executorDeserializeCpuTime" : 50590196,
  "executorRunTime" : 85065,
  "executorCpuTime" : 51632795229,
  "resultSize" : 72030,
  "jvmGcTime" : 658,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 2815350507,
  "inputRecords" : 22509897,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "json at NativeMethodAccessorImpl.java:0",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:496)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\npy4j.Gateway.invoke(Gateway.java:306)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.sendCommand(ClientServerConnection.java:257)\npy4j.CallbackClient.sendCommand(CallbackClient.java:384)\npy4j.CallbackClient.sendCommand(CallbackClient.java:356)\npy4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\ncom.sun.proxy.$Proxy86.call(Unknown Source)\ncom.databricks.pipelines.Pipeline$DatasetBuilderImpl.$anonfun$query$1(Pipeline.scala:269)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$3(Pipeline.scala:653)\ncom.databricks.pipelines.Pipeline.withContext(Pipeline.scala:101)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$2(Pipeline.scala:653)\nscala.util.Try$.apply(Try.scala:213)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 158, 156, 157, 155 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 1717272504,
    "JVMOffHeapMemory" : 204263248,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 5354493,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 5354493,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 2451453,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 46,
    "MinorGCTime" : 369,
    "MajorGCCount" : 5,
    "MajorGCTime" : 383,
    "TotalGCTime" : 752
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 36,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:31:05.689GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:05.707GMT",
  "completionTime" : "2022-12-20T20:31:05.760GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7730993,
  "executorRunTime" : 25,
  "executorCpuTime" : 23935391,
  "resultSize" : 4743,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 552,
  "shuffleReadBytes" : 552,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 150, 149 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 35,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 148, 145, 147, 146, 139, 142, 144, 141, 140, 143 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 34,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 138, 136, 137 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 33,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:31:05.568GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:05.603GMT",
  "completionTime" : "2022-12-20T20:31:05.666GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9946722,
  "executorRunTime" : 30,
  "executorCpuTime" : 26255258,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 3,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 1006,
  "shuffleReadBytes" : 1006,
  "shuffleReadRecords" : 3,
  "shuffleWriteBytes" : 552,
  "shuffleWriteTime" : 345109,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 148, 145, 147, 146, 139, 142, 144, 141, 140, 143 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 32,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 138, 136, 137 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 31,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 3,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 3,
  "submissionTime" : "2022-12-20T20:31:05.424GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:05.429GMT",
  "completionTime" : "2022-12-20T20:31:05.453GMT",
  "executorDeserializeTime" : 3,
  "executorDeserializeCpuTime" : 5147191,
  "executorRunTime" : 7,
  "executorCpuTime" : 6653692,
  "resultSize" : 3333,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 1006,
  "shuffleWriteTime" : 1260230,
  "shuffleWriteRecords" : 3,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 138, 136, 137 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 30,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:31:04.434GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:04.454GMT",
  "completionTime" : "2022-12-20T20:31:04.510GMT",
  "executorDeserializeTime" : 7,
  "executorDeserializeCpuTime" : 7737082,
  "executorRunTime" : 27,
  "executorCpuTime" : 25575781,
  "resultSize" : 4740,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 551,
  "shuffleReadBytes" : 551,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 125, 124 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 29,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 123, 119, 118, 114, 121, 120, 116, 115, 117, 122 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 28,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 113, 112, 111 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 27,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:31:04.293GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:04.352GMT",
  "completionTime" : "2022-12-20T20:31:04.419GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8278600,
  "executorRunTime" : 32,
  "executorCpuTime" : 27659837,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 3,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 1002,
  "shuffleReadBytes" : 1002,
  "shuffleReadRecords" : 3,
  "shuffleWriteBytes" : 551,
  "shuffleWriteTime" : 991626,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 123, 119, 118, 114, 121, 120, 116, 115, 117, 122 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 26,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 113, 112, 111 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 25,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 3,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 3,
  "submissionTime" : "2022-12-20T20:31:04.135GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:04.142GMT",
  "completionTime" : "2022-12-20T20:31:04.171GMT",
  "executorDeserializeTime" : 3,
  "executorDeserializeCpuTime" : 4957960,
  "executorRunTime" : 7,
  "executorCpuTime" : 6880101,
  "resultSize" : 3333,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 1002,
  "shuffleWriteTime" : 1902549,
  "shuffleWriteRecords" : 3,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 113, 112, 111 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 24,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:31:03.019GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:03.039GMT",
  "completionTime" : "2022-12-20T20:31:03.100GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8204906,
  "executorRunTime" : 29,
  "executorCpuTime" : 26415965,
  "resultSize" : 4733,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 540,
  "shuffleReadBytes" : 540,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 100, 99 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 23,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 98, 97, 95, 90, 94, 93, 92, 91, 89, 96 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 22,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 88, 86, 87 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 21,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:31:02.840GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:02.924GMT",
  "completionTime" : "2022-12-20T20:31:02.999GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9449020,
  "executorRunTime" : 39,
  "executorCpuTime" : 31235929,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 3,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 995,
  "shuffleReadBytes" : 995,
  "shuffleReadRecords" : 3,
  "shuffleWriteBytes" : 540,
  "shuffleWriteTime" : 604116,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 98, 97, 95, 90, 94, 93, 92, 91, 89, 96 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 20,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 88, 86, 87 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 19,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 3,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 3,
  "submissionTime" : "2022-12-20T20:31:02.594GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:02.598GMT",
  "completionTime" : "2022-12-20T20:31:02.625GMT",
  "executorDeserializeTime" : 5,
  "executorDeserializeCpuTime" : 6207120,
  "executorRunTime" : 6,
  "executorCpuTime" : 7161147,
  "resultSize" : 3333,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 995,
  "shuffleWriteTime" : 1359533,
  "shuffleWriteRecords" : 3,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 88, 86, 87 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 18,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:31:00.826GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:00.865GMT",
  "completionTime" : "2022-12-20T20:31:00.942GMT",
  "executorDeserializeTime" : 8,
  "executorDeserializeCpuTime" : 8881060,
  "executorRunTime" : 31,
  "executorCpuTime" : 28045989,
  "resultSize" : 5045,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 855,
  "shuffleReadBytes" : 855,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 63, 62 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 17,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "default",
  "rddIds" : [ 59, 53, 57, 54, 56, 58, 50, 52, 51, 55 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 16,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 49, 48, 47 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 15,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:31:00.603GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:00.712GMT",
  "completionTime" : "2022-12-20T20:31:00.800GMT",
  "executorDeserializeTime" : 9,
  "executorDeserializeCpuTime" : 9007110,
  "executorRunTime" : 52,
  "executorCpuTime" : 42629023,
  "resultSize" : 2563,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 5,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 3001,
  "shuffleReadBytes" : 3001,
  "shuffleReadRecords" : 5,
  "shuffleWriteBytes" : 855,
  "shuffleWriteTime" : 352509,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:364)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$1(Snapshot.scala:247)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 59, 53, 57, 54, 56, 58, 50, 52, 51, 55 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 14,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 49, 48, 47 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 13,
  "attemptId" : 0,
  "numTasks" : 5,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 5,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 5,
  "submissionTime" : "2022-12-20T20:31:00.189GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:31:00.193GMT",
  "completionTime" : "2022-12-20T20:31:00.242GMT",
  "executorDeserializeTime" : 12,
  "executorDeserializeCpuTime" : 12580742,
  "executorRunTime" : 14,
  "executorCpuTime" : 12888649,
  "resultSize" : 5555,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 3001,
  "shuffleWriteTime" : 2413266,
  "shuffleWriteRecords" : 5,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 49, 48, 47 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 12,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:30:56.822GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:30:56.842GMT",
  "completionTime" : "2022-12-20T20:30:59.460GMT",
  "executorDeserializeTime" : 114,
  "executorDeserializeCpuTime" : 113971279,
  "executorRunTime" : 2451,
  "executorCpuTime" : 1988163048,
  "resultSize" : 5899,
  "jvmGcTime" : 174,
  "resultSerializationTime" : 4,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 14606,
  "outputRecords" : 10,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 8,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 5817,
  "shuffleReadBytes" : 5817,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "write at TransactionalWriteEdge.scala:413",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:330)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$6(DeltaLogging.scala:123)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:106)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperation$5(DeltaLogging.scala:122)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 46 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 938870080,
    "JVMOffHeapMemory" : 187555184,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 2015121,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 2015121,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 143743,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 30,
    "MinorGCTime" : 257,
    "MajorGCCount" : 4,
    "MajorGCTime" : 241,
    "TotalGCTime" : 498
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 11,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "default",
  "rddIds" : [ 44, 40, 39, 36, 37, 41, 43, 38 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 10,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2022-12-20T20:30:55.068GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:30:56.155GMT",
  "completionTime" : "2022-12-20T20:30:56.602GMT",
  "executorDeserializeTime" : 60,
  "executorDeserializeCpuTime" : 58635122,
  "executorRunTime" : 781,
  "executorCpuTime" : 248585047,
  "resultSize" : 26178,
  "jvmGcTime" : 18,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 268697600,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 5817,
  "shuffleWriteTime" : 296307,
  "shuffleWriteRecords" : 10,
  "name" : "execute at DeltaOptimizedWriterExec.scala:127",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.getShuffleRDD(DeltaOptimizedWriterExec.scala:127)\ncom.databricks.sql.transaction.tahoe.perf.DeltaOptimizedWriterExec.doExecute(DeltaOptimizedWriterExec.scala:208)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:225)\norg.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:269)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\norg.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:265)\norg.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:221)\norg.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:298)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$8(TransactionalWriteEdge.scala:413)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:240)\norg.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:388)\norg.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:187)\norg.apache.spark.sql.SparkSession.withActive(SparkSession.scala:973)\norg.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:142)\norg.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:338)\ncom.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFiles$1(TransactionalWriteEdge.scala:342)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:158)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:145)",
  "schedulingPool" : "event-log-persistence",
  "rddIds" : [ 44, 40, 39, 36, 37, 41, 43, 38 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 9,
  "attemptId" : 0,
  "numTasks" : 21,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 21,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 21,
  "submissionTime" : "2022-12-20T20:30:43.606GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:30:43.614GMT",
  "completionTime" : "2022-12-20T20:31:00.788GMT",
  "executorDeserializeTime" : 2014,
  "executorDeserializeCpuTime" : 564596041,
  "executorRunTime" : 120631,
  "executorCpuTime" : 61157069689,
  "resultSize" : 72068,
  "jvmGcTime" : 2061,
  "resultSerializationTime" : 12,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 2815338927,
  "inputRecords" : 22509897,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "json at NativeMethodAccessorImpl.java:0",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:496)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\npy4j.Gateway.invoke(Gateway.java:306)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.sendCommand(ClientServerConnection.java:257)\npy4j.CallbackClient.sendCommand(CallbackClient.java:384)\npy4j.CallbackClient.sendCommand(CallbackClient.java:356)\npy4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\ncom.sun.proxy.$Proxy86.call(Unknown Source)\ncom.databricks.pipelines.Pipeline$DatasetBuilderImpl.$anonfun$query$1(Pipeline.scala:269)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$3(Pipeline.scala:653)\ncom.databricks.pipelines.Pipeline.withContext(Pipeline.scala:101)\ncom.databricks.pipelines.Pipeline$$anon$1.$anonfun$call$2(Pipeline.scala:653)\nscala.util.Try$.apply(Try.scala:213)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 35, 32, 33, 34 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 938870080,
    "JVMOffHeapMemory" : 187555184,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 2015121,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 2015121,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 143743,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 30,
    "MinorGCTime" : 257,
    "MajorGCCount" : 4,
    "MajorGCTime" : 241,
    "TotalGCTime" : 498
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 8,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:30:26.270GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:30:26.512GMT",
  "completionTime" : "2022-12-20T20:30:27.218GMT",
  "executorDeserializeTime" : 355,
  "executorDeserializeCpuTime" : 355114679,
  "executorRunTime" : 309,
  "executorCpuTime" : 274240073,
  "resultSize" : 3578,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at EventLogSparkSQL.scala:96",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.pipelines.execution.core.log.EventLogSparkSQL$.$anonfun$toProto$1(EventLogSparkSQL.scala:96)\ncom.databricks.pipelines.util.SparkSessionUtils$.withSQLConf(SparkSessionUtils.scala:19)\ncom.databricks.pipelines.execution.core.log.EventLogSparkSQL$.toProto(EventLogSparkSQL.scala:96)\ncom.databricks.pipelines.execution.core.log.DataPlaneInstanceEventReader.$anonfun$fetchEventsFromDelta$2(DataPlaneInstanceEventReader.scala:147)\ncom.databricks.pipelines.execution.core.monitoring.DeltaPipelinesUsageLogging.$anonfun$recordPipelinesOperation$2(DeltaPipelinesUsageLogging.scala:105)\ncom.databricks.pipelines.execution.core.monitoring.DeltaPipelinesUsageLogging.$anonfun$recordPipelinesOperation$5(DeltaPipelinesUsageLogging.scala:125)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)\ncom.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:507)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:528)\ncom.databricks.logging.Log4jUsageLoggingShim$.$anonfun$withAttributionContext$1(Log4jUsageLoggingShim.scala:32)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\ncom.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:94)\ncom.databricks.logging.Log4jUsageLoggingShim$.withAttributionContext(Log4jUsageLoggingShim.scala:30)\ncom.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:283)\ncom.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:282)\ncom.databricks.pipelines.execution.core.monitoring.PublicLogging.withAttributionContext(DeltaPipelinesUsageLogging.scala:24)\ncom.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:318)\ncom.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:303)\ncom.databricks.pipelines.execution.core.monitoring.PublicLogging.withAttributionTags(DeltaPipelinesUsageLogging.scala:24)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 31, 28, 30, 29 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 780083040,
    "JVMOffHeapMemory" : 144526176,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 456506,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 456506,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 23888,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 12,
    "MinorGCTime" : 109,
    "MajorGCCount" : 4,
    "MajorGCTime" : 241,
    "TotalGCTime" : 350
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 7,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:30:24.062GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:30:24.066GMT",
  "completionTime" : "2022-12-20T20:30:24.128GMT",
  "executorDeserializeTime" : 3,
  "executorDeserializeCpuTime" : 2883134,
  "executorRunTime" : 26,
  "executorCpuTime" : 19727941,
  "resultSize" : 1778,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at DataPlaneEventLog.scala:582",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.pipelines.execution.core.log.DataPlaneEventLog.$anonfun$queryMaxPersistedControlPlaneSeqNo$1(DataPlaneEventLog.scala:582)\nscala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)\ncom.databricks.pipelines.execution.core.monitoring.DeltaPipelinesUsageLogging.$anonfun$recordPipelinesOperation$2(DeltaPipelinesUsageLogging.scala:105)\ncom.databricks.pipelines.execution.core.monitoring.DeltaPipelinesUsageLogging.$anonfun$recordPipelinesOperation$5(DeltaPipelinesUsageLogging.scala:125)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)\ncom.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:507)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:528)\ncom.databricks.logging.Log4jUsageLoggingShim$.$anonfun$withAttributionContext$1(Log4jUsageLoggingShim.scala:32)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\ncom.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:94)\ncom.databricks.logging.Log4jUsageLoggingShim$.withAttributionContext(Log4jUsageLoggingShim.scala:30)\ncom.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:283)\ncom.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:282)\ncom.databricks.pipelines.execution.core.monitoring.PublicLogging.withAttributionContext(DeltaPipelinesUsageLogging.scala:24)\ncom.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:318)\ncom.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:303)\ncom.databricks.pipelines.execution.core.monitoring.PublicLogging.withAttributionTags(DeltaPipelinesUsageLogging.scala:24)\ncom.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:502)\ncom.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:422)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 24, 23 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 6,
  "attemptId" : 0,
  "numTasks" : 0,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "collect at DataPlaneEventLog.scala:582",
  "details" : "org.apache.spark.sql.Dataset.collect(Dataset.scala:3221)\ncom.databricks.pipelines.execution.core.log.DataPlaneEventLog.$anonfun$queryMaxPersistedControlPlaneSeqNo$1(DataPlaneEventLog.scala:582)\nscala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)\ncom.databricks.pipelines.execution.core.monitoring.DeltaPipelinesUsageLogging.$anonfun$recordPipelinesOperation$2(DeltaPipelinesUsageLogging.scala:105)\ncom.databricks.pipelines.execution.core.monitoring.DeltaPipelinesUsageLogging.$anonfun$recordPipelinesOperation$5(DeltaPipelinesUsageLogging.scala:125)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:413)\ncom.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:507)\ncom.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:528)\ncom.databricks.logging.Log4jUsageLoggingShim$.$anonfun$withAttributionContext$1(Log4jUsageLoggingShim.scala:32)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\ncom.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:94)\ncom.databricks.logging.Log4jUsageLoggingShim$.withAttributionContext(Log4jUsageLoggingShim.scala:30)\ncom.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:283)\ncom.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:282)\ncom.databricks.pipelines.execution.core.monitoring.PublicLogging.withAttributionContext(DeltaPipelinesUsageLogging.scala:24)\ncom.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:318)\ncom.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:303)\ncom.databricks.pipelines.execution.core.monitoring.PublicLogging.withAttributionTags(DeltaPipelinesUsageLogging.scala:24)\ncom.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:502)\ncom.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:422)",
  "schedulingPool" : "default",
  "rddIds" : [ 22, 19, 21, 20 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 5,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:30:15.293GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:30:15.343GMT",
  "completionTime" : "2022-12-20T20:30:17.657GMT",
  "executorDeserializeTime" : 110,
  "executorDeserializeCpuTime" : 108365081,
  "executorRunTime" : 2167,
  "executorCpuTime" : 2013776807,
  "resultSize" : 5069,
  "jvmGcTime" : 103,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 1,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 835,
  "shuffleReadBytes" : 835,
  "shuffleReadRecords" : 1,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:377)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:363)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 14, 13 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 455660928,
    "JVMOffHeapMemory" : 133887888,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 1002774,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 1002774,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 21409,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 12,
    "MinorGCTime" : 109,
    "MajorGCCount" : 4,
    "MajorGCTime" : 241,
    "TotalGCTime" : 350
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 4,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "first at Snapshot.scala:252",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:377)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:363)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)",
  "schedulingPool" : "default",
  "rddIds" : [ 12, 6, 10, 8, 5, 3, 9, 7, 11, 4 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "SKIPPED",
  "stageId" : 3,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 2, 1, 0 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 2,
  "attemptId" : 0,
  "numTasks" : 1,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 1,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 1,
  "submissionTime" : "2022-12-20T20:30:11.590GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:30:11.854GMT",
  "completionTime" : "2022-12-20T20:30:15.252GMT",
  "executorDeserializeTime" : 553,
  "executorDeserializeCpuTime" : 552742150,
  "executorRunTime" : 2792,
  "executorCpuTime" : 2641678504,
  "resultSize" : 2601,
  "jvmGcTime" : 16,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 33619968,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 3,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 1188,
  "shuffleReadBytes" : 1188,
  "shuffleReadRecords" : 3,
  "shuffleWriteBytes" : 835,
  "shuffleWriteTime" : 501614,
  "shuffleWriteRecords" : 1,
  "name" : "first at Snapshot.scala:252",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.Dataset.first(Dataset.scala:2978)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$4(Snapshot.scala:252)\ncom.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:80)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:173)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:171)\ncom.databricks.sql.transaction.tahoe.Snapshot.recordFrameProfile(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$3(Snapshot.scala:248)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$computedState$2(Snapshot.scala:248)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:377)\ncom.databricks.backend.daemon.driver.ProgressReporter$.withStatusCode(ProgressReporter.scala:363)\ncom.databricks.spark.util.SparkDatabricksProgressReporter$.withStatusCode(ProgressReporter.scala:34)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode(DeltaProgressReporterEdge.scala:30)\ncom.databricks.sql.transaction.tahoe.util.DeltaProgressReporterEdge.withStatusCode$(DeltaProgressReporterEdge.scala:25)\ncom.databricks.sql.transaction.tahoe.Snapshot.withStatusCode(Snapshot.scala:67)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 12, 6, 10, 8, 5, 3, 9, 7, 11, 4 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
}, {
  "status" : "SKIPPED",
  "stageId" : 1,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 0,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 0,
  "executorDeserializeTime" : 0,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 0,
  "executorCpuTime" : 0,
  "resultSize" : 0,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "toRdd at StateCache.scala:60",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "default",
  "rddIds" : [ 2, 1, 0 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0
}, {
  "status" : "COMPLETE",
  "stageId" : 0,
  "attemptId" : 0,
  "numTasks" : 3,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 3,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 3,
  "submissionTime" : "2022-12-20T20:30:09.225GMT",
  "firstTaskLaunchedTime" : "2022-12-20T20:30:09.359GMT",
  "completionTime" : "2022-12-20T20:30:10.915GMT",
  "executorDeserializeTime" : 2667,
  "executorDeserializeCpuTime" : 1582994126,
  "executorRunTime" : 567,
  "executorCpuTime" : 282381706,
  "resultSize" : 3561,
  "jvmGcTime" : 330,
  "resultSerializationTime" : 3,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 1188,
  "shuffleWriteTime" : 47035180,
  "shuffleWriteRecords" : 3,
  "name" : "toRdd at StateCache.scala:60",
  "description" : "com.databricks.pipelines.execution.service.Star...",
  "details" : "org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:252)\ncom.databricks.sql.transaction.tahoe.util.StateCache$CachedDS.<init>(StateCache.scala:60)\ncom.databricks.sql.transaction.tahoe.util.StateCache.$anonfun$cacheDS$1(StateCache.scala:110)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS(StateCache.scala:110)\ncom.databricks.sql.transaction.tahoe.util.StateCache.cacheDS$(StateCache.scala:109)\ncom.databricks.sql.transaction.tahoe.Snapshot.cacheDS(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.$anonfun$cachedState$1(Snapshot.scala:197)\ncom.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\ncom.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\ncom.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:123)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag(DeltaLogging.scala:185)\ncom.databricks.sql.transaction.tahoe.metering.DeltaLogging.withDmqTag$(DeltaLogging.scala:183)\ncom.databricks.sql.transaction.tahoe.Snapshot.withDmqTag(Snapshot.scala:67)\ncom.databricks.sql.transaction.tahoe.Snapshot.cachedState$lzycompute(Snapshot.scala:197)",
  "schedulingPool" : "3203420821677671534",
  "rddIds" : [ 2, 1, 0 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0,
    "TotalGCTime" : 0
  }
} ]